import tkinter as tk
from tkinter import ttk, filedialog, messagebox
from tkinterdnd2 import DND_FILES, TkinterDnD
import os
import pandas as pd
import openai
import json
import re
import itertools
from collections import Counter
import logging


# API anahtarÄ±nÄ± .env dosyasÄ±ndan al
open_ai_key = "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"

logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(levelname)s - %(message)s',
    filename='app.log'
)

class color():
    BLUE = "\033[34m"
    CYAN = "\033[36m"
    MAGENTA = "\033[35m"
    GREEN = "\033[32m"
    RED = "\033[31m"
    YELLOW = "\033[33m"
    RESET = "\033[0m"
class Df_Get():
    def merged_noduplicate_df(klasor_yolu):
        """
        KlasÃ¶rdeki tÃ¼m .csv dosyalarÄ±nÄ± birleÅŸtirir,
        Keyword, Volume ve Difficulty sÃ¼tunlarÄ±na gÃ¶re tekrarlÄ± satÄ±rlarÄ± kaldÄ±rÄ±r,
        tÃ¼m sÃ¼tunlarÄ± saklayarak bir DataFrame dÃ¶ndÃ¼rÃ¼r.
        """
        print("DEBUG: merged_noduplicate_df() baÅŸlatÄ±ldÄ±. KlasÃ¶r:", klasor_yolu)
        try:
            csv_dosyalar = [f for f in os.listdir(klasor_yolu) if f.endswith('.csv')]
            print("DEBUG: Bulunan CSV dosyalarÄ±:", csv_dosyalar)
            if not csv_dosyalar:
                raise ValueError("KlasÃ¶rde hiÃ§ .csv dosyasÄ± bulunamadÄ±!")

            dataframes = []
            for dosya in csv_dosyalar:
                df_temp = pd.read_csv(os.path.join(klasor_yolu, dosya))
                print(f"DEBUG: {dosya} okundu, ÅŸekli: {df_temp.shape}")
                dataframes.append(df_temp)

            # BÃ¼tÃ¼n CSV'ler birleÅŸtiriliyor
            birlesik_df = pd.concat(dataframes, ignore_index=True)

            # Ã–ncelikle, Difficulty sÃ¼tununa gÃ¶re azalan sÄ±rayla sÄ±ralÄ±yoruz
            birlesik_df.sort_values(by="Difficulty", ascending=False, inplace=True)

            # Sadece Keyword sÃ¼tunundaki tekrarlarÄ± kaldÄ±rÄ±p,
            # en yÃ¼ksek Difficulty deÄŸerine sahip satÄ±rÄ± tutuyoruz
            birlesik_df.drop_duplicates(subset=["Keyword"], keep="first", ignore_index=True, inplace=True)

            print("DEBUG: BirleÅŸtirilmiÅŸ DataFrame ÅŸekli:", birlesik_df.shape)
            return birlesik_df

        except Exception as e:
            raise ValueError(f"CSV birleÅŸtirme hatasÄ±: {e}")

    def kvd_df(df,limit):
        df = df[(df["Volume"] >= 20) & (df["Difficulty"] <= limit)]
        df.loc[:, "Volume"] = pd.to_numeric(df["Volume"], errors="coerce")
        df = df.dropna(subset=["Volume"])  
        df["Volume"] = df["Volume"].astype(int)
        df.sort_values(by="Volume", ascending=False, inplace=True)
        df = df[["Keyword", "Volume", "Difficulty"]].dropna()
        print("DEBUG: FiltrelenmiÅŸ ve sÄ±ralanmÄ±ÅŸ KVD CSV:\n", df)
        return df



    def kelime_frekans_df(df, openai_api_key):
        print("DEBUG: kelime_frekans_df() baÅŸlatÄ±ldÄ±.")
        openai.api_key = openai_api_key  # Global openai kullanÄ±lacak
        kelimeler = " ".join(df["Keyword"].astype(str)).split()
        print("DEBUG: BirleÅŸtirilmiÅŸ kelimeler:", kelimeler)
        kelime_sayaci = Counter(kelimeler)
        df_kf = pd.DataFrame(kelime_sayaci.items(), columns=["Kelime", "Frekans"]).sort_values(by="Frekans", ascending=False)
        print("DEBUG: Frekans DataFrame'i:\n", df_kf)
        return df_kf


    def without_branded_kf_df_get(df_kf, openai_api_key):
        """
        Branded kelimeleri ve yasaklÄ± kelimeleri DataFrame'den filtreler.
        
        Args:
            df_kf (pd.DataFrame): Kelime ve Frekans sÃ¼tunlarÄ± olan DataFrame
            openai_api_key (str): OpenAI API anahtarÄ±
        
        Returns:
            pd.DataFrame: FiltrelenmiÅŸ DataFrame
        """
        try:
            word_list = df_kf['Kelime'].tolist()

            yasakli_kelimeler = [
    "free", "new", "best", "top", "iphone", "ipad", "android", "google", "store", 
    "download", "downloads", "for", "apple", "with", "yours", "a", "about", "above", "after", "again", "against", "all", 
    "am", "an", "and", "any", "app", "are", "aren't", "as", "at", "be", "because", "been", "before", "being", "below", 
    "between", "both", "but", "by", "can't", "cannot", "could", "couldn't", "did", "didn't", "do", "does", "doesn't", 
    "doing", "don't", "down", "during", "each", "few", "from", "further", "had", "hadn't", "has", "hasn't", "have", 
    "haven't", "having", "he", "he'd", "he'll", "he's", "her", "here", "here's", "hers", "herself", "him", "himself", 
    "his", "how", "how's", "i", "i'd", "i'll", "i'm", "i've", "if", "in", "into", "is", "isn't", "it", "it's", "its", 
    "itself", "let's", "me", "more", "most", "mustn't", "my", "myself", "no", "nor", "not", "of", "off", "on", "once", 
    "only", "or", "other", "ought", "our", "ours", "ourselves", "out", "over", "own", "same", "shan't", "she", "she'd", 
    "she'll", "she's", "should", "shouldn't", "so", "some", "such", "than", "that", "that's", "the", "their", "theirs", 
    "them", "themselves", "then", "there", "there's", "these", "they", "they'd", "they'll", "they're", "they've", "this", 
    "those", "through", "to", "too", "under", "until", "up", "very", "was", "wasn't", "we", "we'd", "we'll", "we're", 
    "we've", "were", "weren't", "what", "what's", "when", "when's", "where", "where's", "which", "while", "who", "who's", 
    "whom", "why", "why's", "won't", "would", "wouldn't", "you", "you'd", "you'll", "you're", "you've", "your", "yours", 
    "yourself", "yourselves"]

            openai.api_key = openai_api_key

            system_prompt = """
You are an expert in identifying branded words and proper nouns. Your task is to determine if the given words are branded words or proper nouns (like "Williams", "Sherwin", etc.).
You need to identify and return only the words that are branded or proper nouns from the provided list.

Here is the task in detail:
1. Review the following list of words.
2. Identify the branded words and proper nouns.
3. Return the list of identified branded words and proper nouns in the following format:

Example:
- Input: ["Apple", "car", "Sherwin", "painting"]
- Output: ["Apple", "Sherwin"]

*Important*: 
- Only include the branded words and proper nouns in the returned list, and avoid any other words."""  # Mevcut system prompt
            user_prompt = f"""
            Here is the list of words:
            {word_list}

            Return the list of branded words and proper nouns in the following format:
            ["word1", "word2", "word3"]
            """

            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0,
                max_tokens=150
            )

            answer = response["choices"][0]["message"]["content"].strip()
            print(f'{color.RED}DEBUG:BRANDED API yanÄ±tÄ±:{color.RESET} {answer}')

            try:
                branded_data = json.loads(answer)
                print("DEBUG: JSON baÅŸarÄ±yla ayrÄ±ÅŸtÄ±rÄ±ldÄ±:", branded_data)  # JSON Ã§Ä±ktÄ±sÄ±nÄ± kontrol et
                branded_words = [str(item).lower() for item in branded_data] if isinstance(branded_data, list) else []
            except json.JSONDecodeError:
                print("DEBUG: JSON ayrÄ±ÅŸtÄ±rma hatasÄ±, manuel iÅŸleme yapÄ±lÄ±yor")
                cleaned = answer.replace("[", "").replace("]", "").replace('"', '').strip()
                branded_words = [w.strip().lower() for w in cleaned.split(",") if w.strip()]
                print("DEBUG: Manuel temizlenmiÅŸ veri:", branded_words)  # Manuel iÅŸlenen veriyi kontrol et


            # Kelime filtresi oluÅŸtur ve mask ile filtreleme yap
            mask = ~(df_kf['Kelime'].str.lower().isin(branded_words) | 
                    df_kf['Kelime'].str.lower().isin(yasakli_kelimeler))

            # FiltrelenmiÅŸ DataFrame'i oluÅŸtur
            filtered_df = df_kf[mask].copy()

            print(f"DEBUG: FiltrelenmiÅŸ kelime sayÄ±sÄ±: {len(filtered_df)}")
            return filtered_df

        except Exception as e:
            print(f"HATA: {str(e)}")
            return pd.DataFrame(columns=['Kelime', 'Frekans']) 

    def aggregate_frequencies(df):
        """
        AynÄ± kelimeleri birleÅŸtirerek frekans deÄŸerlerini toplar.
        
        Args:
            df (pd.DataFrame): "Kelime" ve "Frekans" sÃ¼tunlarÄ± olan DataFrame.

        Returns:
            pd.DataFrame: AynÄ± kelimelerin frekanslarÄ±nÄ±n toplandÄ±ÄŸÄ± yeni DataFrame.
        """
        try:
            if df is None or df.empty:
                print("\033[31mHATA: BoÅŸ veya geÃ§ersiz DataFrame\033[0m")
                return pd.DataFrame(columns=['Kelime', 'Frekans'])

            # FrekanslarÄ± aynÄ± kelimeler iÃ§in toplama
            aggregated_df = df.groupby("Kelime", as_index=False)["Frekans"].sum()

            print("\033[32mDEBUG: Frekanslar birleÅŸtirildi.\033[0m")
            return aggregated_df

        except Exception as e:
            print(f"\033[31mHATA: Genel hata: {str(e)}\033[0m")
            return pd.DataFrame(columns=['Kelime', 'Frekans'])

    def without_suffixes_df_get(kf_df, selected_country,openai_api_key):
        """
        Kelimelerin Ã§oÄŸul eklerini kaldÄ±rÄ±r ve tekil formlarÄ±nÄ± dÃ¶ndÃ¼rÃ¼r.

        Args:
            kf_df (pd.DataFrame): "Kelime" ve "Frekans" sÃ¼tunlarÄ± olan DataFrame.
            openai_api_key (str): OpenAI API anahtarÄ±.

        Returns:
            pd.DataFrame: Ä°ÅŸlenmiÅŸ DataFrame veya hata durumunda orijinal DataFrame.
        """
        try:
            if kf_df is None or kf_df.empty:
                print("\033[31mHATA: BoÅŸ veya geÃ§ersiz DataFrame\033[0m")
                return pd.DataFrame(columns=['Kelime', 'Frekans'])  # BoÅŸ DataFrame dÃ¶ndÃ¼r

            keyword_list = kf_df['Kelime'].dropna().tolist()
            if not keyword_list:
                print("\033[33mUYARI: Kelime listesi boÅŸ\033[0m")
                return pd.DataFrame(columns=['Kelime', 'Frekans'])  # BoÅŸ DataFrame dÃ¶ndÃ¼r

            openai.api_key = openai_api_key
            print(f"{color.CYAN}DEBUG: SUFFÄ°XES COUNTRY:{selected_country}{color.RESET}")
            system_prompt = f"""
            You are an expert in language processing. Your task is:
1. Given a Python list of keywords in the language relevant to the market of {selected_country},
2. Remove only the plural suffixes from each word to return the singular/base form. For example, if the keywords are in English (as in the {selected_country} market when applicable), remove plural suffixes such as -s, -es, and -ies. If the keywords are in another language, apply the appropriate plural suffix removal rules according to the language conventions of {selected_country}.
3. If a word does not end with any of these plural suffixes, leave it unchanged.
4. Provide the final answer strictly as a Python list of strings.
Example:
- Input: ["cats", "boxes", "stories", "apple"]
- Output: ["cat", "box", "story", "apple"]

**WARNING**: Only remove plural suffixes. Do not remove any other suffix or modify the word in any other way.
"""

            user_prompt = f"""
            Here is the list of words:
            {keyword_list}

            Return the processed list in JSON list format. For example:
            ["word1","word2","word3"]
            """

            try:
                response = openai.ChatCompletion.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    temperature=0,
                    request_timeout=60  # API gecikme hatalarÄ±na karÅŸÄ± Ã¶nlem
                )

                answer = response["choices"][0]["message"]["content"].strip()
                print(f"\033[34mDEBUG: Suffixes API yanÄ±tÄ±: {answer}\033[0m")

                # YanÄ±tÄ±n baÅŸÄ±nda ve sonunda Ã¼Ã§lÃ¼ tÄ±rnak iÃ§eren kod bloÄŸu olup olmadÄ±ÄŸÄ±nÄ± kontrol et ve temizle
                if answer.startswith("```json") or answer.startswith("```python"):
                    answer = answer.split("```")[1]  # Ä°lk Ã¼Ã§lÃ¼ tÄ±rnaÄŸÄ± kaldÄ±r
                    answer = answer.replace("json", "").replace("python", "").strip()  # Gereksiz etiketleri kaldÄ±r
                    answer = answer.split("```")[0]  # KapanÄ±ÅŸ Ã¼Ã§lÃ¼ tÄ±rnaÄŸÄ±nÄ± kaldÄ±r

                try:
                    base_form_list = json.loads(answer)

                    if not isinstance(base_form_list, list) or not base_form_list:
                        raise ValueError("API yanÄ±tÄ± geÃ§erli bir liste deÄŸil veya boÅŸ.")

                    # Liste uzunluÄŸu ile orijinal kelime listesinin uzunluÄŸu eÅŸleÅŸmiyorsa
                    if len(base_form_list) != len(keyword_list):
                        print(f"\033[33mUYARI: API yanÄ±t uzunluÄŸu ({len(base_form_list)}) keyword listesi uzunluÄŸu ({len(keyword_list)}) ile eÅŸleÅŸmiyor. Orijinal liste kullanÄ±lacak.\033[0m")
                        base_form_list = keyword_list  # Orijinal listeyi kullan

                    # Frekans sÃ¼tunundaki boÅŸ deÄŸerleri doldur
                    kf_df['Frekans'] = kf_df['Frekans'].fillna(0)

                    # Yeni DataFrame oluÅŸtur
                    result_df = pd.DataFrame({
                        'Kelime': base_form_list,
                        'Frekans': kf_df['Frekans']
                    })
                    result_df=Df_Get.aggregate_frequencies(result_df)
                    result_df = result_df.sort_values(by='Frekans', ascending=False)

                    print(f"\033[32mDEBUG: Ä°ÅŸlenmiÅŸ kelime sayÄ±sÄ±: {len(result_df)}\033[0m")
                    return pd.DataFrame(result_df)

                except json.JSONDecodeError as e:
                    print(f"\033[31mHATA: JSON ayrÄ±ÅŸtÄ±rma hatasÄ±: {str(e)}\033[0m")
                    return kf_df  # JSON hatasÄ± olursa orijinal DataFrame'i dÃ¶ndÃ¼r

            except Exception as e:
                print(f"\033[31mHATA: API Ã§aÄŸrÄ±sÄ± veya iÅŸleme hatasÄ±: {str(e)}\033[0m")
                return kf_df  # API hatasÄ±nda orijinal DataFrame'i dÃ¶ndÃ¼r

        except Exception as e:
            print(f"\033[31mHATA: Genel hata: {str(e)}\033[0m")
            return pd.DataFrame(columns=['Kelime', 'Frekans'])  # Genel hata durumunda boÅŸ DataFrame dÃ¶ndÃ¼r



    def gpt_Title_Subtitle_df_get(df, app_name,selected_country ,openai_api_key, retry_count=0, max_retries=3):
        print(f"DEBUG: gpt_Title_Subtitle_df() baÅŸlatÄ±ldÄ±. retry_count={retry_count}")
        openai.api_key = openai_api_key
        print(f"{color.YELLOW}gpt_Title_Subtitle_df_get iÃ§in kullanÄ±lan df:\n{df}{color.RESET}")
        df_sorted = df.sort_values(by='Frekans', ascending=False)
        top_keywords = df_sorted['Kelime'].tolist()
        print("DEBUG: En sÄ±k kullanÄ±lan kelimeler:", top_keywords)

        prompt_system = f'''
    You are an experienced ASO (App Store Optimization) expert. Your task is to generate optimized Title and Subtitle for an app based on the provided keyword data.
    I will provide you with a list of keywords sorted by frequency. Based on this information, your task is to generate the most optimized Title and Subtitle for an app's App Store page. Here are the detailed rules:
    You are an experienced ASO (App Store Optimization) expert. Your task is to generate optimized Title and Subtitle for an app based on the provided keyword data, taking into account the market characteristics of the selected country: **{selected_country}**.
I will provide you with a list of keywords sorted by frequency. Based on this information, your task is to generate the most optimized Title and Subtitle for an app's App Store page for the {selected_country} market. Here are the detailed rules:

    1. **Title**:
    - Must include the app name: **{app_name}**
    - The title must be no longer than **30 characters** and no shorter than **25 characters**.
    - Use the most frequent keywords first, prioritizing those at the beginning of the provided list.
    - Ensure that the titles are unique and not repetitive; each generated title should use a different combination of keywords.
    - **Do not include any of the following words like: "and", "or", "your", "my", "with", etc.**

    2. **Subtitle**:
    - It must not exceed **30 characters** and no shorter than **25 characters**.
    - Do not repeat any keywords used in the Title.
    - Use the most frequent keywords first, prioritizing those at the beginning of the provided list.
    - Ensure that the subtitles are unique and distinct from each other.
    - **Do not include any of the following words like: "and", "or", "your", "my", "with".**

    3. **Important**:
    - Focus on using keywords from the beginning of the provided list, where the frequency values are higher.
    - Make sure the Title and Subtitle align with these rules to maximize the app's visibility and effectiveness in the App Store.
    - **Do not include any of the following words like: "and", "or", "your", "my", "with".**
    - *Only generate 5 title and 5 subtitle*
    '''

        # User Prompt: sadece 1 set baÅŸlÄ±k ve alt baÅŸlÄ±k Ã¼retmesini istiyoruz
        prompt_user = f'''
    Here are the most frequent keywords:
    {','.join(top_keywords)}
    - **The title and subtitle must be no longer than 30 characters and no shorter than 25 characters.**
    - **Do not include any of the following words like: "and", "or", "your", "my", "with".**
    - *Only generate 5 title and 5 subtitle*
    **Provide the output strictly in the following JSON format:**
    json
    {{
    "data": [
        {{"Title": "Generated Title", "Subtitle": "Generated Subtitle"}},
        {{"Title": "Generated Title", "Subtitle": "Generated Subtitle"}},
        {{"Title": "Generated Title", "Subtitle": "Generated Subtitle"}},
        {{"Title": "Generated Title", "Subtitle": "Generated Subtitle"}},
        {{"Title": "Generated Title", "Subtitle": "Generated Subtitle"}}
    ]
    }}
    '''
        print('\033[31m\033[44mDEBUG: OpenAI isteÄŸi hazÄ±rlanÄ±yor\033[0m')
        try:
            response = openai.ChatCompletion.create(
                model="chatgpt-4o-latest",
                messages=[
                    {"role": "system", "content": prompt_system},
                    {"role": "user", "content": prompt_user}
                ],
                temperature=0.7,
                max_tokens=539,
            )
            text_output = response['choices'][0]['message']['content']
            def parse_openai_json(text_output):
                # 1) ÃœÃ§lÃ¼ tÄ±rnaklar arasÄ±nÄ± yakala
                match = re.search(r'```json\s*(\{.*?\})\s*```', text_output, re.DOTALL)

                if match:
                    json_text = match.group(1)
                    print("DEBUG: JSON formatÄ± bulundu.")
                else:
                    # match yoksa, belki de ChatGPT "json" arasÄ±na almadÄ±,
                    # o yÃ¼zden tamamÄ±nÄ± kullan
                    json_text = text_output
                    print("DEBUG: TÃ¼m metin JSON olarak kullanÄ±lacak.")

                # 2) Temizleme adÄ±mlarÄ±
                json_text = json_text.strip()
                # Ã‡ift tÄ±rnaklarÄ± standart ASCII tÄ±rnak haline getirelim:
                json_text = json_text.replace("â€œ", "\"").replace("â€", "\"")
                # BOM karakteri vs. kaldÄ±rmak iÃ§in encode-decode
                json_text = json_text.encode("utf-8", "ignore").decode("utf-8", "ignore")

                # 3) Parse et
                output_data = json.loads(json_text)
                return output_data

            try:
                parsed = parse_openai_json(text_output)
                print(parsed)
            except json.JSONDecodeError as e:
                print("JSON hatasÄ± yakalandÄ±:", e)
                    # SÃ¼tun adlarÄ±nÄ± manuel belirliyoruz

            title_stitle_df = pd.DataFrame(parse_openai_json(text_output)["data"], columns=["Title", "Subtitle"])
            print("DEBUG: API yanÄ±tÄ±ndan oluÅŸturulan DataFrame:\n", title_stitle_df)

            # unused_keywords_list ve diÄŸer listeleri baÅŸlatÄ±yoruz
            unused_keywords_list = []  
            title_len_list = []
            subtitle_len_list = []
            toplam_keywords_lenght_list=[]

            # Her bir satÄ±r iÃ§in iÅŸlemi baÅŸlatÄ±yoruz
            for index, row in title_stitle_df.iterrows():
                # Title ve Subtitle'daki kelimeleri ayÄ±rÄ±yoruz
                top_keywords_for_for = set()
                top_keywords_for_for = top_keywords
                title_words = set(row["Title"].split())  
                subtitle_words = set(row["Subtitle"].split())  

                title_len_list.append(len(row["Title"]))
                subtitle_len_list.append(len(row["Subtitle"]))

                # Title ve Subtitle'daki tÃ¼m kelimeleri birleÅŸtiriyoruz
                used_keywords = title_words.union(subtitle_words)
                used_keywords = set(item.lower() for item in used_keywords)
                print("\033[32mDEBUG: Used_Keyword Ã‡Ä±ktÄ±sÄ±: \033[0m", used_keywords)

                # unused_keywords listesini top_keywords'tan used_keywords'leri Ã§Ä±kararak oluÅŸturuyoruz
                unused_keywords = [kw for kw in top_keywords_for_for if kw.lower() not in used_keywords]

                print("\033[33mUnused_Keyword:\033[0m", unused_keywords)

                # unused_keywords'i virgÃ¼lle ayÄ±rarak birleÅŸtiriyoruz
                result_str = ""
                for keyword in unused_keywords:
                    candidate = keyword if result_str == "" else result_str + "," + keyword
                    try:
                        # candidate 100 karakterden uzun olmasÄ±n
                        if len(candidate) <= 100:
                            result_str = candidate
                        else:
                            toplam_keywords_lenght_list.append(len(result_str))
                            break  # 100 karakteri aÅŸarsa, dÃ¶ngÃ¼ sonlanÄ±r
                    except ValueError as e:
                        # Hata mesajÄ±nda belirli bir ifadeyi kontrol edebilirsiniz
                        if "Length of values" in str(e) and "does not match length of index" in str(e):
                            print("DEBUG: unused_keywords_list uzunluÄŸu DataFrame indeks uzunluÄŸu ile uyuÅŸmuyor!")
                            toplam_keywords_lenght_list.append(len(result_str))
                        else:
                            # EÄŸer hata farklÄ±ysa, hatayÄ± yeniden fÄ±rlatÄ±yoruz.
                            raise


                # unused_keywords_list'e her satÄ±r iÃ§in sonuÃ§larÄ± ekliyoruz
                print("\033[34mresult_str:\n\033[0m", result_str)
                unused_keywords_list.append(result_str)

            # unused_keywords_list'i df_output'a yeni bir sÃ¼tun olarak ekliyoruz
            title_stitle_df["Keywords"] = unused_keywords_list
            title_stitle_df["Keywords_Lenght"]=toplam_keywords_lenght_list

            title_stitle_df["Title_Lenght"] = title_len_list
            title_stitle_df["Subtitle_Lenght"] = subtitle_len_list

            # SonuÃ§larÄ± yazdÄ±rÄ±yoruz
            print("DEBUG: Son DataFrame (gpt_Title_Subtitle_df()):\n", title_stitle_df)

            return title_stitle_df

        except (json.JSONDecodeError, ValueError, KeyError) as e:
            print("DEBUG: gpt_Title_Subtitle_df() hatasÄ±:", e)
            return pd.DataFrame(columns=["Title", "Subtitle"])

    def find_matching_keywords(title_subtitle_df, merged_df):
        print(f"\033[34mDEBUG: find_matching_keywords() baÅŸladÄ±.\033[0m")
        results = []
        matched_keywords_result=[]

        # Title_Subtitle tablosundaki HER SATIR iÃ§in ayrÄ± ayrÄ± iÅŸlem yapacaÄŸÄ±z
        for gpt_idx, gpt_row in title_subtitle_df.iterrows():
            # ğŸ“Œ Title, Subtitle, ve Keywords sÃ¼tunundaki kelimeleri al (kÃ¼Ã§Ã¼k harfe Ã§evirerek)
            title_words = set(str(gpt_row['Title']).lower().split()) if pd.notna(gpt_row['Title']) else set()
            subtitle_words = set(str(gpt_row['Subtitle']).lower().split()) if pd.notna(gpt_row['Subtitle']) else set()
            additional_words = set(str(gpt_row['Keywords']).lower().split(',')) if 'Keywords' in gpt_row and pd.notna(gpt_row['Keywords']) else set()

            # ğŸ“Œ TÃ¼m kelimeleri birleÅŸtir
            combined_words = title_words.union(subtitle_words).union(additional_words)
            print(f"\033[35mDEBUG: Ä°ÅŸlenen Title_Subtitle satÄ±rÄ± {gpt_idx}, Kelimeler: {combined_words}\033[0m")

            matched_keywords = []
            total_volume = 0
            total_difficulty = 0
            ort_volume=0
            ort_difficulty=0
            counter=0

            # ğŸ“Œ merged_df iÃ§indeki tÃ¼m satÄ±rlarÄ± tek tek kontrol et
            for _, merged_row in merged_df.iterrows():
                keyword_value = merged_row.get('Keyword')

                if pd.isna(keyword_value) or not isinstance(keyword_value, str):
                    continue  # GeÃ§erli bir string deÄŸilse atla

                # Keyword'Ã¼ kelimelere bÃ¶l ve kÃ¼Ã§Ã¼k harf yap
                keyword_words = set(keyword_value.lower().split())

                # EÄŸer tÃ¼m kelimeler combined_words iÃ§inde varsa, eÅŸleÅŸme bulduk
                if keyword_words.issubset(combined_words):
                    matched_keywords.append(keyword_value)
                    total_volume += merged_row['Volume']
                    total_difficulty += merged_row['Difficulty']
                    counter+=1
                    ort_difficulty=round(total_difficulty / counter, 3)
                    ort_volume=round(total_volume/counter,3)
                    matched_keywords_result.append({
                    'Matched Keywords': merged_row['Keyword'],
                    'Volume':merged_row['Volume'],
                    'Difficulty':merged_row['Difficulty']
                    })

                    print(f"\033[32mDEBUG: EÅŸleÅŸme! '{keyword_value}' (Vol: {merged_row['Volume']}, Diff: {merged_row['Difficulty']})\033[0m")

            # ğŸ“Œ EÄŸer eÅŸleÅŸme bulunduysa, tabloya ekle


            results.append({
                'Title': gpt_row['Title'],
                'Subtitle': gpt_row['Subtitle'],
                'Keywords': gpt_row['Keywords'],
                'Title Lenght':gpt_row['Title_Lenght'],
                'Subtitle Lenght':gpt_row['Subtitle_Lenght'],
                'Keywords Lenght':gpt_row['Keywords_Lenght'],
                'Total Volume': total_volume,
                'Total Difficulty': total_difficulty,
                'Avarage Volume': ort_volume,
                'Avarage Difficulty':ort_difficulty,
                'Renklenen Keywords SayÄ±sÄ±':counter


            })

        print(f"\033[34mDEBUG: find_matching_keywords() tamamlandÄ±.\033[0m")
        return pd.DataFrame(results),pd.DataFrame(matched_keywords_result)



class AutocompleteCombobox(ttk.Combobox):
        def set_completion_list(self, completion_list):
            """ Combobox seÃ§enek listesini ayarlar ve filtreleme iÃ§in gerekli ayarlarÄ± yapar. """
            self._completion_list = sorted(completion_list, key=str.lower)
            self['values'] = self._completion_list
            self.bind('<KeyRelease>', self._handle_keyrelease)

        def _handle_keyrelease(self, event):
            current_text = self.get()
            if current_text == '':
                self['values'] = self._completion_list
            else:
                filtered = [item for item in self._completion_list if current_text.lower() in item.lower()]
                self['values'] = filtered if filtered else self._completion_list

class Table_Tool():

    def __init__(self,root):
        self.root = root
        self.root.title("ASO Generate Tool")
        self.root.geometry("1000x600")
        self.folder_path = tk.StringVar()
        self.difficulty_limit = tk.StringVar(value="20")
        self.open_ai_key=open_ai_key

        self.current_table_name= tk.StringVar(value="Tablo")
        self.merged_noduplicate_df = None
        self.kvd_df = None
        self.kelime_frekans_df = None
        self.without_branded_df = None
        self.without_suffixes_df = None
        self.gpt_title_subtitle_df = None
        self.matching_keywords_df_ts= None
        self.matching_keywords_df= None
        self.selected_countyr= None

        self.setup_ui()
    def setup_ui(self):
        """ ArayÃ¼z bileÅŸenlerini oluÅŸtur. """
        try:
            # ğŸ“Œ SÃ¼rÃ¼kle & BÄ±rak KlasÃ¶r AlanÄ±
            self.dnd_frame = tk.LabelFrame(self.root, text="", width=350, height=150, relief=tk.RIDGE, bd=2)
            self.dnd_frame.place(x=10, y=10)
            self.dnd_frame.drop_target_register(DND_FILES)
            self.dnd_frame.dnd_bind("<<Drop>>", self.drop)
            self.info_label = tk.Label(self.dnd_frame, text="\n\t\t\t\t\t\t\t\n\n\nCSV DosyasÄ±nÄ± SÃ¼rÃ¼kle BÄ±rak\n\t\t\t\t\t\t\t\n\n\n", bg="lightgray")
            self.info_label.pack(expand=True)

            # ğŸ“Œ Ãœlke SeÃ§imi iÃ§in AutocompleteCombobox
            ttk.Label(self.root, text="Select Country:", font=("Arial", 10, "bold")).place(x=160, y=180)
            self.country_var = tk.StringVar()
            self.countrychoosen = AutocompleteCombobox(self.root, width=27, textvariable=self.country_var)

            # Ãœlke listesini tanÄ±mlÄ±yoruz:
            countries = (
                "Afghanistan", "United Arab Emirates", "Antigua and Barbuda", "Anguilla", "Albania", "Armenia", "Angola",
                "Argentina", "Austria", "Australia", "Azerbaijan", "Barbados", "Belgium", "Bosnia and Herzegovina",
                "Burkina Faso", "Bulgaria", "Bahrain", "Benin", "Bermuda", "Brunei", "Bolivia", "Brazil", "Bahamas", "Bhutan",
                "Botswana", "Belarus", "Belize", "Cameroon", "Canada", "Congo, Republic of the", "Switzerland", "Cote d'Ivoire",
                "Chile", "China mainland", "Colombia", "Congo, Democratic Republic of the", "Costa Rica", "Cape Verde",
                "Cyprus", "Czech Republic", "Germany", "Denmark", "Dominica", "Dominican Republic", "Algeria", "Ecuador",
                "Estonia", "Egypt", "Spain", "Finland", "Fiji", "Micronesia", "France", "Gabon", "United Kingdom", "Grenada",
                "Georgia", "Ghana", "Gambia", "Greece", "Guatemala", "Guinea-Bissau", "Guyana", "Hong Kong", "Honduras",
                "Croatia", "Hungary", "Indonesia", "Ireland", "Israel", "India", "Iraq", "Iceland", "Italy", "Jamaica", "Jordan",
                "Japan", "Kenya", "Kyrgyzstan", "Cambodia", "St. Kitts and Nevis", "Republic of Korea", "Kuwait",
                "Cayman Islands", "Kazakhstan", "Laos", "Lebanon", "Libya", "St. Lucia", "Sri Lanka", "Liberia", "Lithuania",
                "Luxembourg", "Latvia", "Morocco", "Moldova", "Maldives", "Madagascar", "North Macedonia", "Mali", "Myanmar",
                "Mongolia", "Montenegro", "Macau", "Mauritania", "Montserrat", "Malta", "Mauritius", "Malawi", "Mexico",
                "Malaysia", "Mozambique", "Namibia", "Niger", "Nigeria", "Nicaragua", "Netherlands", "Norway", "Nepal", "Nauru",
                "New Zealand", "Oman", "Panama", "Peru", "Papua New Guinea", "Philippines", "Pakistan", "Poland", "Portugal",
                "Palau", "Paraguay", "Qatar", "Romania", "Russia", "Rwanda", "Saudi Arabia", "Solomon Islands", "Seychelles",
                "Sweden", "Singapore", "Slovenia", "Slovakia", "Sierra Leone", "Senegal", "Suriname", "Serbia",
                "Sao Tome and Principe", "El Salvador", "Eswatini", "Turks and Caicos Islands", "Chad", "Thailand", "Tajikistan",
                "Turkmenistan", "Tunisia", "Tonga", "Turkey", "Trinidad and Tobago", "Taiwan", "Tanzania", "Ukraine", "Uganda",
                "United States", "Uruguay", "Uzbekistan", "St. Vincent and the Grenadines", "Venezuela", "British Virgin Islands",
                "Vietnam", "Vanuatu", "Kosovo", "Yemen", "South Africa", "Zambia", "Zimbabwe"
            )
            # SeÃ§enek listesini ayarla:
            self.countrychoosen.set_completion_list(countries)
            self.countrychoosen.place(x=180, y=180)
            self.countrychoosen.current(155)


            # ğŸ“Œ Difficulty Limit GiriÅŸi
            tk.Label(self.root, text="Difficulty SÄ±nÄ±r:", font=("Arial", 10, "bold")).place(x=20, y=180)
            self.difficulty_entry = tk.Entry(self.root, textvariable=self.difficulty_limit, width=5)
            self.difficulty_entry.place(x=120, y=183)




            # ğŸ“Œ Butonlar (Tablolar)
            button_width, button_height = 300, 35
            start_y = 220  # ButonlarÄ±n baÅŸlangÄ±Ã§ Y konumu

            tk.Button(self.root, text="BirleÅŸtirilmiÅŸ Ana Tablo", command=self.show_merged_noduplicate_table).place(x=20, y=start_y, width=button_width, height=button_height)
            tk.Button(self.root, text="Keyword_Volume_Difficulty Tablosu", command=self.show_kvd_table).place(x=20, y=start_y + 40, width=button_width, height=button_height)
            tk.Button(self.root, text="Kelime FrekansÄ± GÃ¶ster", command=self.show_kelime_frekans_table).place(x=20, y=start_y + 80, width=button_width, height=button_height)
            tk.Button(self.root, text="Branded Kelimelerden AyrÄ±ÅŸtÄ±rÄ±lmÄ±ÅŸ Tablo", command=self.show_without_branded_df).place(x=20, y=start_y + 120, width=button_width, height=button_height)
            tk.Button(self.root, text="Eklerinden AyrÄ±lmÄ±ÅŸ Kelime Frekans Tablosu", command=self.show_without_suffixes_df).place(x=20, y=start_y + 160, width=button_width, height=button_height)
            tk.Button(self.root, text="Title Subtitle Tablosu", command=lambda: self.show_gpt_title_stitle_df(self.app_name_var.get())).place(x=20, y=start_y + 200, width=button_width, height=button_height)

            # ğŸ“Œ App Name GiriÅŸi
            self.app_name_var = tk.StringVar()  
            tk.Entry(self.root, textvariable=self.app_name_var).place(x=140, y=start_y + 280, width=180, height=30)
            tk.Label(self.root, text="Uygulama Ä°smi:", font=("Arial", 10, "bold")).place(x=20, y=start_y + 280)

            # ğŸ“Œ Tablo BaÅŸlÄ±ÄŸÄ±
            self.table_title_label = tk.Label(self.root, textvariable=self.current_table_name, font=("Arial", 14, "bold"))
            self.table_title_label.place(x=380, y=10)

            # ğŸ“Œ Tablo GÃ¶sterme AlanÄ± (SaÄŸ Tarafta)
            self.frame = ttk.Frame(self.root)
            self.frame.place(x=380, y=50, width=600, height=500)

            # ğŸ“Œ Tablo iÃ§in Scrollbar
            self.tree_scroll = ttk.Scrollbar(self.frame, orient="vertical")
            self.tree_scroll.pack(side="right", fill="y")



            style = ttk.Style()
            style.configure("Treeview.Heading", font=("Arial", 10, "bold"), background="lightblue", foreground="black")
            self.tree = ttk.Treeview(self.frame, yscrollcommand=self.tree_scroll.set, style="Treeview")

            self.tree = ttk.Treeview(self.frame, yscrollcommand=self.tree_scroll.set)
            self.tree.pack(expand=True, fill="both")
            self.tree_scroll.config(command=self.tree.yview)

            # ğŸ“Œ Ã‡ift tÄ±klama event'ini baÄŸla
            self.tree.bind("<Double-1>", self.on_double_click)

            # ğŸ“Œ Tabloyu Ä°ndir Butonu
            tk.Button(self.root, text="Tabloyu Ä°ndir", command=self.tabloyu_kaydet).place(x=700, y=560, width=200, height=35)

        except Exception as e:
            print(f"\033[31mERROR: setup_ui() iÅŸleminde hata: {e}\033[0m")


    def display_table(self, df):
        """ Verilen DataFrame'i gÃ¶sterir. """
        try:
            if df is None or df.empty:
                messagebox.showwarning("UyarÄ±", "Tablo boÅŸ!")
                return
            self.tree.delete(*self.tree.get_children())
            self.tree['columns'] = list(df.columns)
            self.tree['show'] = 'headings'
            for col in df.columns:
                self.tree.heading(col, text=col)
                self.tree.column(col, width=150, anchor="center")
            for idx, row in df.iterrows():
                self.tree.insert("", "end", values=row.tolist())
        except Exception as e:
            print(f"\033[31mERROR: display_table() iÅŸleminde hata: {e}\033[0m")

    def drop(self, event):
        """ KullanÄ±cÄ± sÃ¼rÃ¼kleyip klasÃ¶rÃ¼ bÄ±raktÄ±ÄŸÄ±nda Ã§aÄŸrÄ±lÄ±r. """
        dropped_folder = event.data.strip().replace('{', '').replace('}', '')
        print("DEBUG: KlasÃ¶r bÄ±rakÄ±ldÄ±:", dropped_folder)
        if os.path.isdir(dropped_folder):
            self.folder_path.set(dropped_folder)
            print("DEBUG: Folder path set:", dropped_folder)
            self.update_table()
        else:
            messagebox.showerror("Hata", "GeÃ§erli bir klasÃ¶r bÄ±rakÄ±nÄ±z!")

    def update_table(self):
        """ CSV dosyalarÄ±nÄ± yÃ¼kler ve temizler. """
        try:
            df = Df_Get.merged_noduplicate_df(self.folder_path.get())
            self.merged_noduplicate_df = df
            limit = float(self.difficulty_limit.get())
            self.kvd_df = Df_Get.kvd_df(df, limit)
            self.kelime_frekans_df = Df_Get.kelime_frekans_df(self.kvd_df,open_ai_key)
            self.without_branded_df=Df_Get.without_branded_kf_df_get(self.kelime_frekans_df,self.open_ai_key)
            #self.without_suffixes_df=pd.DataFrame(Df_Get.without_suffixes_df_get(self.without_branded_df,self.country_var.get(),self.open_ai_key))
            self.current_table=self.merged_noduplicate_df
        except Exception as e:
            print(f"\033[31mERROR: update_table() iÅŸleminde hata: {e}\033[0m")

    def on_double_click(self, event):
        """ Sadece `matching_keywords_df` aÃ§Ä±kken Ã§ift tÄ±klama olayÄ±nÄ± iÅŸler. """
        try:
            if not self.current_table.equals(self.matching_keywords_df_ts):
                messagebox.showerror("Ã‡ift tÄ±klama iÅŸlemi devre dÄ±ÅŸÄ±! (Tablo uygun deÄŸil)!")
                return  # EÄŸer uygun tablo aÃ§Ä±k deÄŸilse Ã§Ä±k

            selected_item = self.tree.selection()
            if not selected_item:
                return  # HiÃ§bir satÄ±r seÃ§ilmediyse Ã§Ä±k

            item_values = self.tree.item(selected_item, "values")  # SatÄ±rÄ±n verilerini al
            title_value = item_values[0]  # Ä°lk sÃ¼tunun Title olduÄŸu varsayÄ±lÄ±yor
            subtitle_value = item_values[1]  # Ä°kinci sÃ¼tunun Subtitle olduÄŸu varsayÄ±lÄ±yor

            # ğŸ“Œ Title ve Subtitle'a gÃ¶re eÅŸleÅŸen kelimeleri al
            matched_keywords_df=self.matching_keywords_df

            # ğŸ“Œ Yeni pencere oluÅŸtur
            popup = tk.Toplevel(self.root)
            popup.title("Matched Keywords Table")
            popup.geometry("800x400")

            # ğŸ“Œ BaÅŸlÄ±k
            tk.Label(popup, text=f"{title_value}, {subtitle_value} Ä°Ã§in Matched Keywords", font=("Arial")).pack(pady=10)

            # ğŸ“Œ Treeview (Tablo) oluÅŸtur
            tree = ttk.Treeview(popup)
            tree["columns"] = list(matched_keywords_df.columns)
            tree["show"] = "headings"

            # ğŸ“Œ SÃ¼tun baÅŸlÄ±klarÄ±nÄ± ekle
            for col in matched_keywords_df.columns:
                tree.heading(col, text=col)
                tree.column(col, anchor="center", width=150)

            # ğŸ“Œ Verileri tabloya ekle
            for _, row in matched_keywords_df.iterrows():
                tree.insert("", "end", values=list(row))

            # ğŸ“Œ Scrollbar ekle
            scrollbar = ttk.Scrollbar(popup, orient="vertical", command=tree.yview)
            tree.configure(yscrollcommand=scrollbar.set)
            scrollbar.pack(side="right", fill="y")

            tree.pack(expand=True, fill="both")

        except Exception as e:
            print(f"\033[31mERROR: on_double_click() iÅŸleminde hata: {e}\033[0m")

    def tabloyu_kaydet(self):
        print("DEBUG: tabloyu_kaydet() baÅŸlatÄ±ldÄ±.")
        if self.current_table is None or self.current_table.empty:
            messagebox.showwarning("UyarÄ±", "Ã–nce bir tablo oluÅŸturmalÄ±sÄ±nÄ±z!")
            return
        file_path = filedialog.asksaveasfilename(defaultextension=".csv", filetypes=[("CSV Files", "*.csv")])
        if file_path:
            self.current_table.to_csv(file_path, index=False)
            print("DEBUG: Tablo kaydedildi. Dosya yolu:", file_path)
            messagebox.showinfo("BaÅŸarÄ±lÄ±", "Tablo baÅŸarÄ±yla kaydedildi!")


    def show_merged_noduplicate_table(self):
        try:
            if self.merged_noduplicate_df is not None:
                self.display_table(self.merged_noduplicate_df)
                self.current_table=self.merged_noduplicate_df
                self.current_table_name.set("BirleÅŸtirilmiÅŸ Ana Tablo")
            else:
                messagebox.showerror("Hata", "BirleÅŸtirilmiÅŸ tablo yÃ¼klenemedi!")
        except Exception as e:
            messagebox.showerror("Hata", f"Tablo gÃ¶sterilirken hata oluÅŸtu: {e}")

    def show_kvd_table(self):
        try:
            if self.kvd_df is not None:
                self.display_table(self.kvd_df)
                self.current_table=self.kvd_df
                self.current_table_name.set("Keywords Volume Difficulty Tablosu")
            else:
                messagebox.showerror("Hata", "BirleÅŸtirilmiÅŸ tablo yÃ¼klenemedi!")
        except Exception as e:
            messagebox.showerror("Hata", f"Tablo gÃ¶sterilirken hata oluÅŸtu: {e}")

    def show_kelime_frekans_table(self):
        try:
            if self.kelime_frekans_df is not None:
                self.display_table(self.kelime_frekans_df)
                self.current_table=self.kelime_frekans_df
                self.current_table_name.set("Kelime Frekans Tablosu")
            else:
                messagebox.showerror("Hata", "BirleÅŸtirilmiÅŸ tablo yÃ¼klenemedi!")
        except Exception as e:
            messagebox.showerror("Hata", f"Tablo gÃ¶sterilirken hata oluÅŸtu: {e}")

    def show_without_suffixes_df(self):
        try:
            if self.merged_noduplicate_df is not None:
                self.without_suffixes_df=pd.DataFrame(Df_Get.without_suffixes_df_get(self.without_branded_df,self.country_var.get(),self.open_ai_key))
                self.display_table(self.without_suffixes_df)
                self.current_table=self.without_suffixes_df
                self.current_table_name.set("Eklerinden AyrÄ±lmÄ±ÅŸ Kelime Frekans Tablosu")
            else:
                messagebox.showerror("Hata", "BirleÅŸtirilmiÅŸ tablo yÃ¼klenemedi!")
        except Exception as e:
            messagebox.showerror("Hata", f"Tablo gÃ¶sterilirken hata oluÅŸtu: {e}")

    def show_without_branded_df(self):
        try:
            if self.without_branded_df is not None:
                self.display_table(self.without_branded_df)
                self.current_table=self.without_branded_df
                self.current_table_name.set("Branded Kelimelerin OlmadÄ±ÄŸÄ± Tablo")
            else:
                messagebox.showerror("Hata", "BirleÅŸtirilmiÅŸ tablo yÃ¼klenemedi!")
        except Exception as e:
            messagebox.showerror("Hata", f"Tablo gÃ¶sterilirken hata oluÅŸtu: {e}")

    def show_gpt_title_stitle_df(self, app_name):
        print("DEBUG: gpt_t_s_k_goster() baÅŸlatÄ±ldÄ±. App Name:", app_name)
        print("DEBUG: Country :", self.country_var.get())
        if self.kelime_frekans_df is None or self.kelime_frekans_df.empty:
            messagebox.showwarning("UyarÄ±", "Ã–nce CSV dosyasÄ±nÄ± yÃ¼kleyin ve iÅŸleyin!")
            return

        # GPT'den gelen DataFrame'i alÄ±yoruz.
        self.gpt_title_subtitle_df = Df_Get.gpt_Title_Subtitle_df_get(
            self.without_suffixes_df, app_name, self.country_var.get(), self.open_ai_key
        )
        print("DEBUG: GPT'den gelen DataFrame:\n", self.gpt_title_subtitle_df)

        # EÄŸer DataFrame boÅŸ ise
        if self.gpt_title_subtitle_df.empty:
            messagebox.showinfo(
                f"{color.RED}Bilgilendirme{color.RESET}\n",
                f"GPT'den dÃ¶nen DataFrame boÅŸ. Difficulty limit {float(self.difficulty_limit.get())+10} artÄ±rÄ±lÄ±yor ve yeniden deneniyor."
            )
            try:
                current_limit = float(self.difficulty_limit.get())
            except ValueError:
                current_limit = float(self.difficulty_limit.get())
            new_limit = current_limit + 10
            self.difficulty_limit.set(str(new_limit))

            # Ä°steÄŸe baÄŸlÄ±: ArayÃ¼zÃ¼ gÃ¼ncellemek iÃ§in setup_ui'Ä± yeniden Ã§aÄŸÄ±rÄ±yoruz.
            self.update_table()
            print(f"{color.YELLOW}DEBUG:Difficulty SÄ±nÄ±r deÄŸeri {self.difficulty_limit} olarak deÄŸiÅŸtirildi{color.RESET}")
            # Fonksiyonu tekrar Ã§aÄŸÄ±rÄ±yoruz.
            self.show_gpt_title_stitle_df(app_name)
            return

        # DataFrame boÅŸ deÄŸilse, eÅŸleÅŸen anahtar kelimeleri bulup tabloyu gÃ¶steriyoruz.
        self.matching_keywords_df_ts, self.matching_keywords_df = Df_Get.find_matching_keywords(
            self.gpt_title_subtitle_df, self.merged_noduplicate_df
        )

        self.display_table(self.matching_keywords_df_ts)
        self.current_table = self.matching_keywords_df_ts
        self.current_table_name.set("Title Subtitle Keywords Tablosu")


    def show_matching_keywords(self):
        #if self.gpt_title_subtitle_df is None or self.merged_noduplicate_df is None:
        #    messagebox.showwarning("UyarÄ±", "Ã–nce gerekli tablolarÄ± oluÅŸturmalÄ±sÄ±nÄ±z!")
        #    return

        self.matching_keywords_df_ts,_= Df_Get.find_matching_keywords(self.gpt_title_subtitle_df, self.merged_noduplicate_df)
        self.display_table(self.matching_keywords_df_ts)
        self.current_table=self.matching_keywords_df_ts
        self.current_table_name.set("EÅŸleÅŸen Anahtar Kelimeler Tablosu")


if __name__ == "__main__":
    root = TkinterDnD.Tk()
    app = Table_Tool(root)
    root.mainloop()