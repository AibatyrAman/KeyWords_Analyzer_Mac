{"ast":null,"code":"// OpenAI API configuration\nconst OPENAI_API_KEY = \"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\";\n\n// Banned words list\nconst BANNED_WORDS = [\"free\", \"new\", \"best\", \"top\", \"iphone\", \"ipad\", \"android\", \"google\", \"store\", \"download\", \"downloads\", \"for\", \"apple\", \"with\", \"yours\", \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"app\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\"];\nexport class TitleSubtitleProcessor {\n  // Step 1: Filter data by Volume and Difficulty\n  static filterKVDData(data, difficultyLimit) {\n    return data.filter(item => item.Volume >= 20 && item.Difficulty <= difficultyLimit).sort((a, b) => b.Volume - a.Volume);\n  }\n\n  // Step 2: Generate word frequency from keywords\n  static generateWordFrequency(data) {\n    const wordCount = {};\n    data.forEach(item => {\n      const words = item.Keyword.toLowerCase().split(/\\s+/);\n      words.forEach(word => {\n        if (word) {\n          wordCount[word] = (wordCount[word] || 0) + 1;\n        }\n      });\n    });\n    return Object.entries(wordCount).map(([word, frequency]) => ({\n      word,\n      frequency\n    })).sort((a, b) => b.frequency - a.frequency);\n  }\n\n  // Step 3: Remove branded words using OpenAI\n  static async removeBrandedWords(wordFrequencies) {\n    try {\n      const words = wordFrequencies.map(wf => wf.word);\n      const systemPrompt = `\nYou are an expert in identifying branded words and proper nouns. Your task is to determine if the given words are branded words or proper nouns (like \"Williams\", \"Sherwin\", etc.).\nYou need to identify and return only the words that are branded or proper nouns from the provided list.\n\nHere is the task in detail:\n1. Review the following list of words.\n2. Identify the branded words and proper nouns.\n3. Return the list of identified branded words and proper nouns in the following format:\n\nExample:\n- Input: [\"Apple\", \"car\", \"Sherwin\", \"painting\"]\n- Output: [\"Apple\", \"Sherwin\"]\n\n*Important*: \n- Only include the branded words and proper nouns in the returned list, and avoid any other words.`;\n      const userPrompt = `\nHere is the list of words:\n${words}\n\nReturn the list of branded words and proper nouns in the following format:\n[\"word1\", \"word2\", \"word3\"]\n`;\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${OPENAI_API_KEY}`\n        },\n        body: JSON.stringify({\n          model: 'gpt-4',\n          messages: [{\n            role: 'system',\n            content: systemPrompt\n          }, {\n            role: 'user',\n            content: userPrompt\n          }],\n          temperature: 0,\n          max_tokens: 150\n        })\n      });\n      const result = await response.json();\n\n      // Check if response is valid\n      if (!result.choices || !result.choices[0] || !result.choices[0].message || !result.choices[0].message.content) {\n        console.error('Invalid OpenAI response:', result);\n        throw new Error('OpenAI API yanıtı geçersiz. Lütfen tekrar deneyin.');\n      }\n      const answer = result.choices[0].message.content.trim();\n      let brandedWords = [];\n      try {\n        brandedWords = JSON.parse(answer);\n      } catch {\n        // Manual parsing if JSON fails\n        const cleaned = answer.replace(/[[\\]\"]/g, '').trim();\n        brandedWords = cleaned.split(',').map(w => w.trim().toLowerCase()).filter(w => w);\n      }\n\n      // Filter out branded words and banned words\n      return wordFrequencies.filter(wf => !brandedWords.includes(wf.word.toLowerCase()) && !BANNED_WORDS.includes(wf.word.toLowerCase()));\n    } catch (error) {\n      console.error('Error removing branded words:', error);\n      // Return original data if API fails\n      return wordFrequencies.filter(wf => !BANNED_WORDS.includes(wf.word.toLowerCase()));\n    }\n  }\n\n  // Step 4: Remove suffixes using OpenAI\n  static async removeSuffixes(wordFrequencies, selectedCountry) {\n    try {\n      const words = wordFrequencies.map(wf => wf.word);\n      const systemPrompt = `\nYou are an expert in language processing. Your task is:\n1. Given a Python list of keywords in the language relevant to the market of ${selectedCountry},\n2. Remove only the plural suffixes from each word to return the singular/base form. For example, if the keywords are in English (as in the ${selectedCountry} market when applicable), remove plural suffixes such as -s, -es, and -ies. If the keywords are in another language, apply the appropriate plural suffix removal rules according to the language conventions of ${selectedCountry}.\n3. If a word does not end with any of these plural suffixes, leave it unchanged.\n4. Provide the final answer strictly as a Python list of strings.\nExample:\n- Input: [\"cats\", \"boxes\", \"stories\", \"apple\"]\n- Output: [\"cat\", \"box\", \"story\", \"apple\"]\n\n**WARNING**: Only remove plural suffixes. Do not remove any other suffix or modify the word in any other way.`;\n      const userPrompt = `\nHere is the list of words:\n${words}\n\nReturn the processed list in JSON list format. For example:\n[\"word1\",\"word2\",\"word3\"]\n`;\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${OPENAI_API_KEY}`\n        },\n        body: JSON.stringify({\n          model: 'gpt-4o',\n          messages: [{\n            role: 'system',\n            content: systemPrompt\n          }, {\n            role: 'user',\n            content: userPrompt\n          }],\n          temperature: 0\n        })\n      });\n      const result = await response.json();\n      const answer = result.choices[0].message.content.trim();\n      let baseForms = [];\n      try {\n        // Clean up the response\n        let cleanedAnswer = answer;\n        if (cleanedAnswer.includes('```json')) {\n          cleanedAnswer = cleanedAnswer.split('```json')[1].split('```')[0];\n        } else if (cleanedAnswer.includes('```python')) {\n          cleanedAnswer = cleanedAnswer.split('```python')[1].split('```')[0];\n        }\n        cleanedAnswer = cleanedAnswer.trim();\n        baseForms = JSON.parse(cleanedAnswer);\n      } catch {\n        console.error('Error parsing suffix removal response');\n        return wordFrequencies; // Return original if parsing fails\n      }\n\n      // Aggregate frequencies for same base forms\n      const aggregated = {};\n      baseForms.forEach((baseForm, index) => {\n        if (index < wordFrequencies.length) {\n          aggregated[baseForm] = (aggregated[baseForm] || 0) + wordFrequencies[index].frequency;\n        }\n      });\n      return Object.entries(aggregated).map(([word, frequency]) => ({\n        word,\n        frequency\n      })).sort((a, b) => b.frequency - a.frequency);\n    } catch (error) {\n      console.error('Error removing suffixes:', error);\n      return wordFrequencies; // Return original if API fails\n    }\n  }\n\n  // Step 5: Generate Title and Subtitle using OpenAI\n  static async generateTitleSubtitle(wordFrequencies, appName, selectedCountry) {\n    try {\n      const topKeywords = wordFrequencies.map(wf => wf.word);\n      const systemPrompt = `\nYou are an experienced ASO (App Store Optimization) expert. Your task is to generate optimized Title and Subtitle for an app based on the provided keyword data, taking into account the market characteristics of the selected country: **${selectedCountry}**.\nI will provide you with a list of keywords sorted by frequency. Based on this information, your task is to generate the most optimized Title and Subtitle for an app's App Store page for the ${selectedCountry} market. Here are the detailed rules:\n\n1. **Title**:\n- Must include the app name: **${appName}**\n- The title must be no longer than **30 characters** and no shorter than **25 characters**.\n- Use the most frequent keywords first, prioritizing those at the beginning of the provided list.\n- Ensure that the titles are unique and not repetitive; each generated title should use a different combination of keywords.\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\", etc.**\n\n2. **Subtitle**:\n- It must not exceed **30 characters** and no shorter than **25 characters**.\n- Do not repeat any keywords used in the Title.\n- Use the most frequent keywords first, prioritizing those at the beginning of the provided list.\n- Ensure that the subtitles are unique and distinct from each other.\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\".**\n\n3. **Important**:\n- Focus on using keywords from the beginning of the provided list, where the frequency values are higher.\n- Make sure the Title and Subtitle align with these rules to maximize the app's visibility and effectiveness in the App Store.\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\".**\n- *Only generate 5 title and 5 subtitle*`;\n      const userPrompt = `\nHere are the most frequent keywords:\n${topKeywords.join(',')}\n- **The title and subtitle must be no longer than 30 characters and no shorter than 25 characters.**\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\".**\n- *Only generate 5 title and 5 subtitle*\n**Provide the output strictly in the following JSON format:**\n{\n\"data\": [\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"}\n]\n}`;\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${OPENAI_API_KEY}`\n        },\n        body: JSON.stringify({\n          model: 'gpt-4o',\n          messages: [{\n            role: 'system',\n            content: systemPrompt\n          }, {\n            role: 'user',\n            content: userPrompt\n          }],\n          temperature: 0.7,\n          max_tokens: 539\n        })\n      });\n      const result = await response.json();\n      const answer = result.choices[0].message.content.trim();\n      let parsedData;\n      try {\n        // Extract JSON from response\n        const jsonMatch = answer.match(/```json\\s*([\\s\\S]*?)\\s*```/);\n        const jsonText = jsonMatch ? jsonMatch[1] : answer;\n        parsedData = JSON.parse(jsonText);\n      } catch {\n        throw new Error('Failed to parse OpenAI response');\n      }\n      const titleSubtitleData = [];\n      parsedData.data.forEach((item, index) => {\n        const title = item.Title;\n        const subtitle = item.Subtitle;\n\n        // Calculate unused keywords\n        const titleWords = new Set(title.toLowerCase().split(/\\s+/));\n        const subtitleWords = new Set(subtitle.toLowerCase().split(/\\s+/));\n        const usedWords = new Set(Array.from(titleWords).concat(Array.from(subtitleWords)));\n        const unusedKeywords = topKeywords.filter(keyword => !usedWords.has(keyword.toLowerCase()));\n        const keywordsString = unusedKeywords.slice(0, 10).join(','); // Limit to first 10\n\n        titleSubtitleData.push({\n          Title: title,\n          Subtitle: subtitle,\n          Keywords: keywordsString,\n          Title_Length: title.length,\n          Subtitle_Length: subtitle.length,\n          Keywords_Length: keywordsString.length,\n          Total_Volume: 0,\n          // Will be calculated in next step\n          Total_Difficulty: 0,\n          // Will be calculated in next step\n          Average_Volume: 0,\n          // Will be calculated in next step\n          Average_Difficulty: 0,\n          // Will be calculated in next step\n          Matched_Keywords_Count: 0 // Will be calculated in next step\n        });\n      });\n      return titleSubtitleData;\n    } catch (error) {\n      console.error('Error generating title subtitle:', error);\n      throw error;\n    }\n  }\n\n  // Step 6: Find matching keywords and calculate scores\n  static findMatchingKeywords(titleSubtitleData, originalData) {\n    const matchedKeywords = [];\n    const updatedTitleSubtitleData = titleSubtitleData.map(item => {\n      var _item$Title, _item$Subtitle, _item$Keywords;\n      const titleWords = new Set(((_item$Title = item.Title) === null || _item$Title === void 0 ? void 0 : _item$Title.toLowerCase().split(/\\s+/)) || []);\n      const subtitleWords = new Set(((_item$Subtitle = item.Subtitle) === null || _item$Subtitle === void 0 ? void 0 : _item$Subtitle.toLowerCase().split(/\\s+/)) || []);\n      const keywordsWords = new Set(((_item$Keywords = item.Keywords) === null || _item$Keywords === void 0 ? void 0 : _item$Keywords.toLowerCase().split(/,/)) || []);\n      const combinedWords = new Set(Array.from(titleWords).concat(Array.from(subtitleWords)).concat(Array.from(keywordsWords)));\n      let totalVolume = 0;\n      let totalDifficulty = 0;\n      let matchedCount = 0;\n      originalData.forEach(row => {\n        const keywordWords = new Set(row.Keyword.toLowerCase().split(/\\s+/));\n\n        // Check if all keyword words are in combined words\n        const isMatch = Array.from(keywordWords).every(word => Array.from(combinedWords).some(combinedWord => combinedWord.includes(word) || word.includes(combinedWord)));\n        if (isMatch) {\n          totalVolume += row.Volume;\n          totalDifficulty += row.Difficulty;\n          matchedCount++;\n          matchedKeywords.push({\n            keyword: row.Keyword,\n            volume: row.Volume,\n            difficulty: row.Difficulty\n          });\n        }\n      });\n      return {\n        ...item,\n        Total_Volume: totalVolume,\n        Total_Difficulty: totalDifficulty,\n        Average_Volume: matchedCount > 0 ? Math.round(totalVolume / matchedCount * 1000) / 1000 : 0,\n        Average_Difficulty: matchedCount > 0 ? Math.round(totalDifficulty / matchedCount * 1000) / 1000 : 0,\n        Matched_Keywords_Count: matchedCount\n      };\n    });\n    return {\n      titleSubtitleData: updatedTitleSubtitleData,\n      matchedKeywords\n    };\n  }\n\n  // Main processing function\n  static async processTitleSubtitle(data, appName, selectedCountry, difficultyLimit) {\n    // Validate inputs\n    if (!data || data.length === 0) {\n      throw new Error('No data provided for processing');\n    }\n    if (!appName || appName.trim() === '') {\n      throw new Error('App name is required');\n    }\n    if (!selectedCountry || selectedCountry.trim() === '') {\n      throw new Error('Country selection is required');\n    }\n\n    // Step 1: Filter KVD data\n    const kvdData = this.filterKVDData(data, difficultyLimit);\n    if (kvdData.length === 0) {\n      throw new Error(`No data found with Volume >= 20 and Difficulty <= ${difficultyLimit}. Try increasing the difficulty limit.`);\n    }\n\n    // Step 2: Generate word frequency\n    const wordFrequencies = this.generateWordFrequency(kvdData);\n    if (wordFrequencies.length === 0) {\n      throw new Error('No word frequencies could be generated from the data');\n    }\n\n    // Step 3: Remove branded words\n    const withoutBranded = await this.removeBrandedWords(wordFrequencies);\n    if (withoutBranded.length === 0) {\n      throw new Error('No words remaining after removing branded words');\n    }\n\n    // Step 4: Remove suffixes\n    const withoutSuffixes = await this.removeSuffixes(withoutBranded, selectedCountry);\n    if (withoutSuffixes.length === 0) {\n      throw new Error('No words remaining after removing suffixes');\n    }\n\n    // Step 5: Generate title and subtitle\n    const titleSubtitleData = await this.generateTitleSubtitle(withoutSuffixes, appName, selectedCountry);\n    if (titleSubtitleData.length === 0) {\n      throw new Error('Failed to generate title and subtitle data');\n    }\n\n    // Step 6: Find matching keywords and calculate scores\n    const result = this.findMatchingKeywords(titleSubtitleData, data);\n    return result;\n  }\n}","map":{"version":3,"names":["OPENAI_API_KEY","BANNED_WORDS","TitleSubtitleProcessor","filterKVDData","data","difficultyLimit","filter","item","Volume","Difficulty","sort","a","b","generateWordFrequency","wordCount","forEach","words","Keyword","toLowerCase","split","word","Object","entries","map","frequency","removeBrandedWords","wordFrequencies","wf","systemPrompt","userPrompt","response","fetch","method","headers","body","JSON","stringify","model","messages","role","content","temperature","max_tokens","result","json","choices","message","console","error","Error","answer","trim","brandedWords","parse","cleaned","replace","w","includes","removeSuffixes","selectedCountry","baseForms","cleanedAnswer","aggregated","baseForm","index","length","generateTitleSubtitle","appName","topKeywords","join","parsedData","jsonMatch","match","jsonText","titleSubtitleData","title","Title","subtitle","Subtitle","titleWords","Set","subtitleWords","usedWords","Array","from","concat","unusedKeywords","keyword","has","keywordsString","slice","push","Keywords","Title_Length","Subtitle_Length","Keywords_Length","Total_Volume","Total_Difficulty","Average_Volume","Average_Difficulty","Matched_Keywords_Count","findMatchingKeywords","originalData","matchedKeywords","updatedTitleSubtitleData","_item$Title","_item$Subtitle","_item$Keywords","keywordsWords","combinedWords","totalVolume","totalDifficulty","matchedCount","row","keywordWords","isMatch","every","some","combinedWord","volume","difficulty","Math","round","processTitleSubtitle","kvdData","withoutBranded","withoutSuffixes"],"sources":["/Users/aibatyr/Documents/GitHub/KeyWords_Analyzer_Web/Keyword_Analyzer_Web/src/utils/titleSubtitleProcessor.ts"],"sourcesContent":["import { KeywordData, TitleSubtitleData } from '../types';\n\n// OpenAI API configuration\nconst OPENAI_API_KEY = \"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\";\n\n// Banned words list\nconst BANNED_WORDS = [\n  \"free\", \"new\", \"best\", \"top\", \"iphone\", \"ipad\", \"android\", \"google\", \"store\", \n  \"download\", \"downloads\", \"for\", \"apple\", \"with\", \"yours\", \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \n  \"am\", \"an\", \"and\", \"any\", \"app\", \"are\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \n  \"between\", \"both\", \"but\", \"by\", \"can't\", \"cannot\", \"could\", \"couldn't\", \"did\", \"didn't\", \"do\", \"does\", \"doesn't\", \n  \"doing\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"from\", \"further\", \"had\", \"hadn't\", \"has\", \"hasn't\", \"have\", \n  \"haven't\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n  \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"isn't\", \"it\", \"it's\", \"its\", \n  \"itself\", \"let's\", \"me\", \"more\", \"most\", \"mustn't\", \"my\", \"myself\", \"no\", \"nor\", \"not\", \"of\", \"off\", \"on\", \"once\", \n  \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"shan't\", \"she\", \"she'd\", \n  \"she'll\", \"she's\", \"should\", \"shouldn't\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \n  \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \n  \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"wasn't\", \"we\", \"we'd\", \"we'll\", \"we're\", \n  \"we've\", \"were\", \"weren't\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \n  \"whom\", \"why\", \"why's\", \"won't\", \"would\", \"wouldn't\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \n  \"yourself\", \"yourselves\"\n];\n\ninterface WordFrequency {\n  word: string;\n  frequency: number;\n}\n\ninterface MatchedKeyword {\n  keyword: string;\n  volume: number;\n  difficulty: number;\n}\n\nexport class TitleSubtitleProcessor {\n  \n  // Step 1: Filter data by Volume and Difficulty\n  static filterKVDData(data: KeywordData[], difficultyLimit: number): KeywordData[] {\n    return data\n      .filter(item => item.Volume >= 20 && item.Difficulty <= difficultyLimit)\n      .sort((a, b) => b.Volume - a.Volume);\n  }\n\n  // Step 2: Generate word frequency from keywords\n  static generateWordFrequency(data: KeywordData[]): WordFrequency[] {\n    const wordCount: Record<string, number> = {};\n    \n    data.forEach(item => {\n      const words = item.Keyword.toLowerCase().split(/\\s+/);\n      words.forEach(word => {\n        if (word) {\n          wordCount[word] = (wordCount[word] || 0) + 1;\n        }\n      });\n    });\n\n    return Object.entries(wordCount)\n      .map(([word, frequency]) => ({ word, frequency }))\n      .sort((a, b) => b.frequency - a.frequency);\n  }\n\n  // Step 3: Remove branded words using OpenAI\n  static async removeBrandedWords(wordFrequencies: WordFrequency[]): Promise<WordFrequency[]> {\n    try {\n      const words = wordFrequencies.map(wf => wf.word);\n      \n      const systemPrompt = `\nYou are an expert in identifying branded words and proper nouns. Your task is to determine if the given words are branded words or proper nouns (like \"Williams\", \"Sherwin\", etc.).\nYou need to identify and return only the words that are branded or proper nouns from the provided list.\n\nHere is the task in detail:\n1. Review the following list of words.\n2. Identify the branded words and proper nouns.\n3. Return the list of identified branded words and proper nouns in the following format:\n\nExample:\n- Input: [\"Apple\", \"car\", \"Sherwin\", \"painting\"]\n- Output: [\"Apple\", \"Sherwin\"]\n\n*Important*: \n- Only include the branded words and proper nouns in the returned list, and avoid any other words.`;\n\n      const userPrompt = `\nHere is the list of words:\n${words}\n\nReturn the list of branded words and proper nouns in the following format:\n[\"word1\", \"word2\", \"word3\"]\n`;\n\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${OPENAI_API_KEY}`\n        },\n        body: JSON.stringify({\n          model: 'gpt-4',\n          messages: [\n            { role: 'system', content: systemPrompt },\n            { role: 'user', content: userPrompt }\n          ],\n          temperature: 0,\n          max_tokens: 150\n        })\n      });\n\n      const result = await response.json();\n      \n      // Check if response is valid\n      if (!result.choices || !result.choices[0] || !result.choices[0].message || !result.choices[0].message.content) {\n        console.error('Invalid OpenAI response:', result);\n        throw new Error('OpenAI API yanıtı geçersiz. Lütfen tekrar deneyin.');\n      }\n      \n      const answer = result.choices[0].message.content.trim();\n      \n      let brandedWords: string[] = [];\n      try {\n        brandedWords = JSON.parse(answer);\n      } catch {\n        // Manual parsing if JSON fails\n        const cleaned = answer.replace(/[[\\]\"]/g, '').trim();\n        brandedWords = cleaned.split(',').map((w: string) => w.trim().toLowerCase()).filter((w: string) => w);\n      }\n\n      // Filter out branded words and banned words\n      return wordFrequencies.filter(wf => \n        !brandedWords.includes(wf.word.toLowerCase()) && \n        !BANNED_WORDS.includes(wf.word.toLowerCase())\n      );\n\n    } catch (error) {\n      console.error('Error removing branded words:', error);\n      // Return original data if API fails\n      return wordFrequencies.filter(wf => !BANNED_WORDS.includes(wf.word.toLowerCase()));\n    }\n  }\n\n  // Step 4: Remove suffixes using OpenAI\n  static async removeSuffixes(wordFrequencies: WordFrequency[], selectedCountry: string): Promise<WordFrequency[]> {\n    try {\n      const words = wordFrequencies.map(wf => wf.word);\n      \n      const systemPrompt = `\nYou are an expert in language processing. Your task is:\n1. Given a Python list of keywords in the language relevant to the market of ${selectedCountry},\n2. Remove only the plural suffixes from each word to return the singular/base form. For example, if the keywords are in English (as in the ${selectedCountry} market when applicable), remove plural suffixes such as -s, -es, and -ies. If the keywords are in another language, apply the appropriate plural suffix removal rules according to the language conventions of ${selectedCountry}.\n3. If a word does not end with any of these plural suffixes, leave it unchanged.\n4. Provide the final answer strictly as a Python list of strings.\nExample:\n- Input: [\"cats\", \"boxes\", \"stories\", \"apple\"]\n- Output: [\"cat\", \"box\", \"story\", \"apple\"]\n\n**WARNING**: Only remove plural suffixes. Do not remove any other suffix or modify the word in any other way.`;\n\n      const userPrompt = `\nHere is the list of words:\n${words}\n\nReturn the processed list in JSON list format. For example:\n[\"word1\",\"word2\",\"word3\"]\n`;\n\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${OPENAI_API_KEY}`\n        },\n        body: JSON.stringify({\n          model: 'gpt-4o',\n          messages: [\n            { role: 'system', content: systemPrompt },\n            { role: 'user', content: userPrompt }\n          ],\n          temperature: 0\n        })\n      });\n\n      const result = await response.json();\n      const answer = result.choices[0].message.content.trim();\n      \n      let baseForms: string[] = [];\n      try {\n        // Clean up the response\n        let cleanedAnswer = answer;\n        if (cleanedAnswer.includes('```json')) {\n          cleanedAnswer = cleanedAnswer.split('```json')[1].split('```')[0];\n        } else if (cleanedAnswer.includes('```python')) {\n          cleanedAnswer = cleanedAnswer.split('```python')[1].split('```')[0];\n        }\n        cleanedAnswer = cleanedAnswer.trim();\n        \n        baseForms = JSON.parse(cleanedAnswer);\n      } catch {\n        console.error('Error parsing suffix removal response');\n        return wordFrequencies; // Return original if parsing fails\n      }\n\n      // Aggregate frequencies for same base forms\n      const aggregated: Record<string, number> = {};\n      baseForms.forEach((baseForm, index) => {\n        if (index < wordFrequencies.length) {\n          aggregated[baseForm] = (aggregated[baseForm] || 0) + wordFrequencies[index].frequency;\n        }\n      });\n\n      return Object.entries(aggregated)\n        .map(([word, frequency]) => ({ word, frequency }))\n        .sort((a, b) => b.frequency - a.frequency);\n\n    } catch (error) {\n      console.error('Error removing suffixes:', error);\n      return wordFrequencies; // Return original if API fails\n    }\n  }\n\n  // Step 5: Generate Title and Subtitle using OpenAI\n  static async generateTitleSubtitle(\n    wordFrequencies: WordFrequency[], \n    appName: string, \n    selectedCountry: string\n  ): Promise<TitleSubtitleData[]> {\n    try {\n      const topKeywords = wordFrequencies.map(wf => wf.word);\n      \n      const systemPrompt = `\nYou are an experienced ASO (App Store Optimization) expert. Your task is to generate optimized Title and Subtitle for an app based on the provided keyword data, taking into account the market characteristics of the selected country: **${selectedCountry}**.\nI will provide you with a list of keywords sorted by frequency. Based on this information, your task is to generate the most optimized Title and Subtitle for an app's App Store page for the ${selectedCountry} market. Here are the detailed rules:\n\n1. **Title**:\n- Must include the app name: **${appName}**\n- The title must be no longer than **30 characters** and no shorter than **25 characters**.\n- Use the most frequent keywords first, prioritizing those at the beginning of the provided list.\n- Ensure that the titles are unique and not repetitive; each generated title should use a different combination of keywords.\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\", etc.**\n\n2. **Subtitle**:\n- It must not exceed **30 characters** and no shorter than **25 characters**.\n- Do not repeat any keywords used in the Title.\n- Use the most frequent keywords first, prioritizing those at the beginning of the provided list.\n- Ensure that the subtitles are unique and distinct from each other.\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\".**\n\n3. **Important**:\n- Focus on using keywords from the beginning of the provided list, where the frequency values are higher.\n- Make sure the Title and Subtitle align with these rules to maximize the app's visibility and effectiveness in the App Store.\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\".**\n- *Only generate 5 title and 5 subtitle*`;\n\n      const userPrompt = `\nHere are the most frequent keywords:\n${topKeywords.join(',')}\n- **The title and subtitle must be no longer than 30 characters and no shorter than 25 characters.**\n- **Do not include any of the following words like: \"and\", \"or\", \"your\", \"my\", \"with\".**\n- *Only generate 5 title and 5 subtitle*\n**Provide the output strictly in the following JSON format:**\n{\n\"data\": [\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"},\n    {\"Title\": \"Generated Title\", \"Subtitle\": \"Generated Subtitle\"}\n]\n}`;\n\n      const response = await fetch('https://api.openai.com/v1/chat/completions', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${OPENAI_API_KEY}`\n        },\n        body: JSON.stringify({\n          model: 'gpt-4o',\n          messages: [\n            { role: 'system', content: systemPrompt },\n            { role: 'user', content: userPrompt }\n          ],\n          temperature: 0.7,\n          max_tokens: 539\n        })\n      });\n\n      const result = await response.json();\n      const answer = result.choices[0].message.content.trim();\n      \n      let parsedData: any;\n      try {\n        // Extract JSON from response\n        const jsonMatch = answer.match(/```json\\s*([\\s\\S]*?)\\s*```/);\n        const jsonText = jsonMatch ? jsonMatch[1] : answer;\n        parsedData = JSON.parse(jsonText);\n      } catch {\n        throw new Error('Failed to parse OpenAI response');\n      }\n\n      const titleSubtitleData: TitleSubtitleData[] = [];\n      \n      parsedData.data.forEach((item: any, index: number) => {\n        const title = item.Title;\n        const subtitle = item.Subtitle;\n        \n        // Calculate unused keywords\n        const titleWords = new Set(title.toLowerCase().split(/\\s+/));\n        const subtitleWords = new Set(subtitle.toLowerCase().split(/\\s+/));\n        const usedWords = new Set(Array.from(titleWords).concat(Array.from(subtitleWords)));\n        \n        const unusedKeywords = topKeywords.filter(keyword => \n          !usedWords.has(keyword.toLowerCase())\n        );\n        \n        const keywordsString = unusedKeywords.slice(0, 10).join(','); // Limit to first 10\n        \n        titleSubtitleData.push({\n          Title: title,\n          Subtitle: subtitle,\n          Keywords: keywordsString,\n          Title_Length: title.length,\n          Subtitle_Length: subtitle.length,\n          Keywords_Length: keywordsString.length,\n          Total_Volume: 0, // Will be calculated in next step\n          Total_Difficulty: 0, // Will be calculated in next step\n          Average_Volume: 0, // Will be calculated in next step\n          Average_Difficulty: 0, // Will be calculated in next step\n          Matched_Keywords_Count: 0 // Will be calculated in next step\n        });\n      });\n\n      return titleSubtitleData;\n\n    } catch (error) {\n      console.error('Error generating title subtitle:', error);\n      throw error;\n    }\n  }\n\n  // Step 6: Find matching keywords and calculate scores\n  static findMatchingKeywords(\n    titleSubtitleData: TitleSubtitleData[], \n    originalData: KeywordData[]\n  ): { titleSubtitleData: TitleSubtitleData[], matchedKeywords: MatchedKeyword[] } {\n    \n    const matchedKeywords: MatchedKeyword[] = [];\n    \n    const updatedTitleSubtitleData = titleSubtitleData.map(item => {\n      const titleWords = new Set(item.Title?.toLowerCase().split(/\\s+/) || []);\n      const subtitleWords = new Set(item.Subtitle?.toLowerCase().split(/\\s+/) || []);\n      const keywordsWords = new Set(item.Keywords?.toLowerCase().split(/,/) || []);\n      \n      const combinedWords = new Set(\n        Array.from(titleWords)\n          .concat(Array.from(subtitleWords))\n          .concat(Array.from(keywordsWords))\n      );\n      \n      let totalVolume = 0;\n      let totalDifficulty = 0;\n      let matchedCount = 0;\n      \n      originalData.forEach(row => {\n        const keywordWords = new Set(row.Keyword.toLowerCase().split(/\\s+/));\n        \n        // Check if all keyword words are in combined words\n        const isMatch = Array.from(keywordWords).every(word => \n          Array.from(combinedWords).some(combinedWord => \n            combinedWord.includes(word) || word.includes(combinedWord)\n          )\n        );\n        \n        if (isMatch) {\n          totalVolume += row.Volume;\n          totalDifficulty += row.Difficulty;\n          matchedCount++;\n          \n          matchedKeywords.push({\n            keyword: row.Keyword,\n            volume: row.Volume,\n            difficulty: row.Difficulty\n          });\n        }\n      });\n      \n      return {\n        ...item,\n        Total_Volume: totalVolume,\n        Total_Difficulty: totalDifficulty,\n        Average_Volume: matchedCount > 0 ? Math.round(totalVolume / matchedCount * 1000) / 1000 : 0,\n        Average_Difficulty: matchedCount > 0 ? Math.round(totalDifficulty / matchedCount * 1000) / 1000 : 0,\n        Matched_Keywords_Count: matchedCount\n      };\n    });\n    \n    return {\n      titleSubtitleData: updatedTitleSubtitleData,\n      matchedKeywords\n    };\n  }\n\n  // Main processing function\n  static async processTitleSubtitle(\n    data: KeywordData[],\n    appName: string,\n    selectedCountry: string,\n    difficultyLimit: number\n  ): Promise<{ titleSubtitleData: TitleSubtitleData[], matchedKeywords: MatchedKeyword[] }> {\n    \n    // Validate inputs\n    if (!data || data.length === 0) {\n      throw new Error('No data provided for processing');\n    }\n    \n    if (!appName || appName.trim() === '') {\n      throw new Error('App name is required');\n    }\n    \n    if (!selectedCountry || selectedCountry.trim() === '') {\n      throw new Error('Country selection is required');\n    }\n    \n    // Step 1: Filter KVD data\n    const kvdData = this.filterKVDData(data, difficultyLimit);\n    if (kvdData.length === 0) {\n      throw new Error(`No data found with Volume >= 20 and Difficulty <= ${difficultyLimit}. Try increasing the difficulty limit.`);\n    }\n    \n    // Step 2: Generate word frequency\n    const wordFrequencies = this.generateWordFrequency(kvdData);\n    if (wordFrequencies.length === 0) {\n      throw new Error('No word frequencies could be generated from the data');\n    }\n    \n    // Step 3: Remove branded words\n    const withoutBranded = await this.removeBrandedWords(wordFrequencies);\n    if (withoutBranded.length === 0) {\n      throw new Error('No words remaining after removing branded words');\n    }\n    \n    // Step 4: Remove suffixes\n    const withoutSuffixes = await this.removeSuffixes(withoutBranded, selectedCountry);\n    if (withoutSuffixes.length === 0) {\n      throw new Error('No words remaining after removing suffixes');\n    }\n    \n    // Step 5: Generate title and subtitle\n    const titleSubtitleData = await this.generateTitleSubtitle(withoutSuffixes, appName, selectedCountry);\n    if (titleSubtitleData.length === 0) {\n      throw new Error('Failed to generate title and subtitle data');\n    }\n    \n    // Step 6: Find matching keywords and calculate scores\n    const result = this.findMatchingKeywords(titleSubtitleData, data);\n    \n    return result;\n  }\n}\n"],"mappings":"AAEA;AACA,MAAMA,cAAc,GAAG,sKAAsK;;AAE7L;AACA,MAAMC,YAAY,GAAG,CACnB,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,QAAQ,EAAE,MAAM,EAAE,SAAS,EAAE,QAAQ,EAAE,OAAO,EAC5E,UAAU,EAAE,WAAW,EAAE,KAAK,EAAE,OAAO,EAAE,MAAM,EAAE,OAAO,EAAE,GAAG,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,SAAS,EAAE,KAAK,EACnH,IAAI,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,KAAK,EAAE,QAAQ,EAAE,IAAI,EAAE,IAAI,EAAE,IAAI,EAAE,SAAS,EAAE,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,OAAO,EACjH,SAAS,EAAE,MAAM,EAAE,KAAK,EAAE,IAAI,EAAE,OAAO,EAAE,QAAQ,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,EAAE,QAAQ,EAAE,IAAI,EAAE,MAAM,EAAE,SAAS,EAChH,OAAO,EAAE,OAAO,EAAE,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,SAAS,EAAE,KAAK,EAAE,QAAQ,EAAE,KAAK,EAAE,QAAQ,EAAE,MAAM,EAC9G,SAAS,EAAE,QAAQ,EAAE,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,SAAS,EAAE,KAAK,EAAE,SAAS,EAChH,KAAK,EAAE,KAAK,EAAE,OAAO,EAAE,GAAG,EAAE,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,IAAI,EAAE,IAAI,EAAE,MAAM,EAAE,IAAI,EAAE,OAAO,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EAChH,QAAQ,EAAE,OAAO,EAAE,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,SAAS,EAAE,IAAI,EAAE,QAAQ,EAAE,IAAI,EAAE,KAAK,EAAE,KAAK,EAAE,IAAI,EAAE,KAAK,EAAE,IAAI,EAAE,MAAM,EACjH,MAAM,EAAE,IAAI,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAE,MAAM,EAAE,WAAW,EAAE,KAAK,EAAE,MAAM,EAAE,KAAK,EAAE,MAAM,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,EAClH,QAAQ,EAAE,OAAO,EAAE,QAAQ,EAAE,WAAW,EAAE,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,EAAE,QAAQ,EAAE,KAAK,EAAE,OAAO,EAAE,QAAQ,EAClH,MAAM,EAAE,YAAY,EAAE,MAAM,EAAE,OAAO,EAAE,SAAS,EAAE,OAAO,EAAE,MAAM,EAAE,QAAQ,EAAE,SAAS,EAAE,SAAS,EAAE,SAAS,EAAE,MAAM,EACpH,OAAO,EAAE,SAAS,EAAE,IAAI,EAAE,KAAK,EAAE,OAAO,EAAE,OAAO,EAAE,IAAI,EAAE,MAAM,EAAE,KAAK,EAAE,QAAQ,EAAE,IAAI,EAAE,MAAM,EAAE,OAAO,EAAE,OAAO,EAChH,OAAO,EAAE,MAAM,EAAE,SAAS,EAAE,MAAM,EAAE,QAAQ,EAAE,MAAM,EAAE,QAAQ,EAAE,OAAO,EAAE,SAAS,EAAE,OAAO,EAAE,OAAO,EAAE,KAAK,EAAE,OAAO,EACpH,MAAM,EAAE,KAAK,EAAE,OAAO,EAAE,OAAO,EAAE,OAAO,EAAE,UAAU,EAAE,KAAK,EAAE,OAAO,EAAE,QAAQ,EAAE,QAAQ,EAAE,QAAQ,EAAE,MAAM,EAAE,OAAO,EACnH,UAAU,EAAE,YAAY,CACzB;AAaD,OAAO,MAAMC,sBAAsB,CAAC;EAElC;EACA,OAAOC,aAAaA,CAACC,IAAmB,EAAEC,eAAuB,EAAiB;IAChF,OAAOD,IAAI,CACRE,MAAM,CAACC,IAAI,IAAIA,IAAI,CAACC,MAAM,IAAI,EAAE,IAAID,IAAI,CAACE,UAAU,IAAIJ,eAAe,CAAC,CACvEK,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACJ,MAAM,GAAGG,CAAC,CAACH,MAAM,CAAC;EACxC;;EAEA;EACA,OAAOK,qBAAqBA,CAACT,IAAmB,EAAmB;IACjE,MAAMU,SAAiC,GAAG,CAAC,CAAC;IAE5CV,IAAI,CAACW,OAAO,CAACR,IAAI,IAAI;MACnB,MAAMS,KAAK,GAAGT,IAAI,CAACU,OAAO,CAACC,WAAW,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC;MACrDH,KAAK,CAACD,OAAO,CAACK,IAAI,IAAI;QACpB,IAAIA,IAAI,EAAE;UACRN,SAAS,CAACM,IAAI,CAAC,GAAG,CAACN,SAAS,CAACM,IAAI,CAAC,IAAI,CAAC,IAAI,CAAC;QAC9C;MACF,CAAC,CAAC;IACJ,CAAC,CAAC;IAEF,OAAOC,MAAM,CAACC,OAAO,CAACR,SAAS,CAAC,CAC7BS,GAAG,CAAC,CAAC,CAACH,IAAI,EAAEI,SAAS,CAAC,MAAM;MAAEJ,IAAI;MAAEI;IAAU,CAAC,CAAC,CAAC,CACjDd,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACY,SAAS,GAAGb,CAAC,CAACa,SAAS,CAAC;EAC9C;;EAEA;EACA,aAAaC,kBAAkBA,CAACC,eAAgC,EAA4B;IAC1F,IAAI;MACF,MAAMV,KAAK,GAAGU,eAAe,CAACH,GAAG,CAACI,EAAE,IAAIA,EAAE,CAACP,IAAI,CAAC;MAEhD,MAAMQ,YAAY,GAAG;AAC3B;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mGAAmG;MAE7F,MAAMC,UAAU,GAAG;AACzB;AACA,EAAEb,KAAK;AACP;AACA;AACA;AACA,CAAC;MAEK,MAAMc,QAAQ,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;QACzEC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UACP,cAAc,EAAE,kBAAkB;UAClC,eAAe,EAAE,UAAUjC,cAAc;QAC3C,CAAC;QACDkC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UACnBC,KAAK,EAAE,OAAO;UACdC,QAAQ,EAAE,CACR;YAAEC,IAAI,EAAE,QAAQ;YAAEC,OAAO,EAAEZ;UAAa,CAAC,EACzC;YAAEW,IAAI,EAAE,MAAM;YAAEC,OAAO,EAAEX;UAAW,CAAC,CACtC;UACDY,WAAW,EAAE,CAAC;UACdC,UAAU,EAAE;QACd,CAAC;MACH,CAAC,CAAC;MAEF,MAAMC,MAAM,GAAG,MAAMb,QAAQ,CAACc,IAAI,CAAC,CAAC;;MAEpC;MACA,IAAI,CAACD,MAAM,CAACE,OAAO,IAAI,CAACF,MAAM,CAACE,OAAO,CAAC,CAAC,CAAC,IAAI,CAACF,MAAM,CAACE,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,IAAI,CAACH,MAAM,CAACE,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACN,OAAO,EAAE;QAC7GO,OAAO,CAACC,KAAK,CAAC,0BAA0B,EAAEL,MAAM,CAAC;QACjD,MAAM,IAAIM,KAAK,CAAC,oDAAoD,CAAC;MACvE;MAEA,MAAMC,MAAM,GAAGP,MAAM,CAACE,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACN,OAAO,CAACW,IAAI,CAAC,CAAC;MAEvD,IAAIC,YAAsB,GAAG,EAAE;MAC/B,IAAI;QACFA,YAAY,GAAGjB,IAAI,CAACkB,KAAK,CAACH,MAAM,CAAC;MACnC,CAAC,CAAC,MAAM;QACN;QACA,MAAMI,OAAO,GAAGJ,MAAM,CAACK,OAAO,CAAC,SAAS,EAAE,EAAE,CAAC,CAACJ,IAAI,CAAC,CAAC;QACpDC,YAAY,GAAGE,OAAO,CAACnC,KAAK,CAAC,GAAG,CAAC,CAACI,GAAG,CAAEiC,CAAS,IAAKA,CAAC,CAACL,IAAI,CAAC,CAAC,CAACjC,WAAW,CAAC,CAAC,CAAC,CAACZ,MAAM,CAAEkD,CAAS,IAAKA,CAAC,CAAC;MACvG;;MAEA;MACA,OAAO9B,eAAe,CAACpB,MAAM,CAACqB,EAAE,IAC9B,CAACyB,YAAY,CAACK,QAAQ,CAAC9B,EAAE,CAACP,IAAI,CAACF,WAAW,CAAC,CAAC,CAAC,IAC7C,CAACjB,YAAY,CAACwD,QAAQ,CAAC9B,EAAE,CAACP,IAAI,CAACF,WAAW,CAAC,CAAC,CAC9C,CAAC;IAEH,CAAC,CAAC,OAAO8B,KAAK,EAAE;MACdD,OAAO,CAACC,KAAK,CAAC,+BAA+B,EAAEA,KAAK,CAAC;MACrD;MACA,OAAOtB,eAAe,CAACpB,MAAM,CAACqB,EAAE,IAAI,CAAC1B,YAAY,CAACwD,QAAQ,CAAC9B,EAAE,CAACP,IAAI,CAACF,WAAW,CAAC,CAAC,CAAC,CAAC;IACpF;EACF;;EAEA;EACA,aAAawC,cAAcA,CAAChC,eAAgC,EAAEiC,eAAuB,EAA4B;IAC/G,IAAI;MACF,MAAM3C,KAAK,GAAGU,eAAe,CAACH,GAAG,CAACI,EAAE,IAAIA,EAAE,CAACP,IAAI,CAAC;MAEhD,MAAMQ,YAAY,GAAG;AAC3B;AACA,+EAA+E+B,eAAe;AAC9F,6IAA6IA,eAAe,mNAAmNA,eAAe;AAC9X;AACA;AACA;AACA;AACA;AACA;AACA,8GAA8G;MAExG,MAAM9B,UAAU,GAAG;AACzB;AACA,EAAEb,KAAK;AACP;AACA;AACA;AACA,CAAC;MAEK,MAAMc,QAAQ,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;QACzEC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UACP,cAAc,EAAE,kBAAkB;UAClC,eAAe,EAAE,UAAUjC,cAAc;QAC3C,CAAC;QACDkC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UACnBC,KAAK,EAAE,QAAQ;UACfC,QAAQ,EAAE,CACR;YAAEC,IAAI,EAAE,QAAQ;YAAEC,OAAO,EAAEZ;UAAa,CAAC,EACzC;YAAEW,IAAI,EAAE,MAAM;YAAEC,OAAO,EAAEX;UAAW,CAAC,CACtC;UACDY,WAAW,EAAE;QACf,CAAC;MACH,CAAC,CAAC;MAEF,MAAME,MAAM,GAAG,MAAMb,QAAQ,CAACc,IAAI,CAAC,CAAC;MACpC,MAAMM,MAAM,GAAGP,MAAM,CAACE,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACN,OAAO,CAACW,IAAI,CAAC,CAAC;MAEvD,IAAIS,SAAmB,GAAG,EAAE;MAC5B,IAAI;QACF;QACA,IAAIC,aAAa,GAAGX,MAAM;QAC1B,IAAIW,aAAa,CAACJ,QAAQ,CAAC,SAAS,CAAC,EAAE;UACrCI,aAAa,GAAGA,aAAa,CAAC1C,KAAK,CAAC,SAAS,CAAC,CAAC,CAAC,CAAC,CAACA,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACnE,CAAC,MAAM,IAAI0C,aAAa,CAACJ,QAAQ,CAAC,WAAW,CAAC,EAAE;UAC9CI,aAAa,GAAGA,aAAa,CAAC1C,KAAK,CAAC,WAAW,CAAC,CAAC,CAAC,CAAC,CAACA,KAAK,CAAC,KAAK,CAAC,CAAC,CAAC,CAAC;QACrE;QACA0C,aAAa,GAAGA,aAAa,CAACV,IAAI,CAAC,CAAC;QAEpCS,SAAS,GAAGzB,IAAI,CAACkB,KAAK,CAACQ,aAAa,CAAC;MACvC,CAAC,CAAC,MAAM;QACNd,OAAO,CAACC,KAAK,CAAC,uCAAuC,CAAC;QACtD,OAAOtB,eAAe,CAAC,CAAC;MAC1B;;MAEA;MACA,MAAMoC,UAAkC,GAAG,CAAC,CAAC;MAC7CF,SAAS,CAAC7C,OAAO,CAAC,CAACgD,QAAQ,EAAEC,KAAK,KAAK;QACrC,IAAIA,KAAK,GAAGtC,eAAe,CAACuC,MAAM,EAAE;UAClCH,UAAU,CAACC,QAAQ,CAAC,GAAG,CAACD,UAAU,CAACC,QAAQ,CAAC,IAAI,CAAC,IAAIrC,eAAe,CAACsC,KAAK,CAAC,CAACxC,SAAS;QACvF;MACF,CAAC,CAAC;MAEF,OAAOH,MAAM,CAACC,OAAO,CAACwC,UAAU,CAAC,CAC9BvC,GAAG,CAAC,CAAC,CAACH,IAAI,EAAEI,SAAS,CAAC,MAAM;QAAEJ,IAAI;QAAEI;MAAU,CAAC,CAAC,CAAC,CACjDd,IAAI,CAAC,CAACC,CAAC,EAAEC,CAAC,KAAKA,CAAC,CAACY,SAAS,GAAGb,CAAC,CAACa,SAAS,CAAC;IAE9C,CAAC,CAAC,OAAOwB,KAAK,EAAE;MACdD,OAAO,CAACC,KAAK,CAAC,0BAA0B,EAAEA,KAAK,CAAC;MAChD,OAAOtB,eAAe,CAAC,CAAC;IAC1B;EACF;;EAEA;EACA,aAAawC,qBAAqBA,CAChCxC,eAAgC,EAChCyC,OAAe,EACfR,eAAuB,EACO;IAC9B,IAAI;MACF,MAAMS,WAAW,GAAG1C,eAAe,CAACH,GAAG,CAACI,EAAE,IAAIA,EAAE,CAACP,IAAI,CAAC;MAEtD,MAAMQ,YAAY,GAAG;AAC3B,6OAA6O+B,eAAe;AAC5P,gMAAgMA,eAAe;AAC/M;AACA;AACA,iCAAiCQ,OAAO;AACxC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,yCAAyC;MAEnC,MAAMtC,UAAU,GAAG;AACzB;AACA,EAAEuC,WAAW,CAACC,IAAI,CAAC,GAAG,CAAC;AACvB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,EAAE;MAEI,MAAMvC,QAAQ,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;QACzEC,MAAM,EAAE,MAAM;QACdC,OAAO,EAAE;UACP,cAAc,EAAE,kBAAkB;UAClC,eAAe,EAAE,UAAUjC,cAAc;QAC3C,CAAC;QACDkC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;UACnBC,KAAK,EAAE,QAAQ;UACfC,QAAQ,EAAE,CACR;YAAEC,IAAI,EAAE,QAAQ;YAAEC,OAAO,EAAEZ;UAAa,CAAC,EACzC;YAAEW,IAAI,EAAE,MAAM;YAAEC,OAAO,EAAEX;UAAW,CAAC,CACtC;UACDY,WAAW,EAAE,GAAG;UAChBC,UAAU,EAAE;QACd,CAAC;MACH,CAAC,CAAC;MAEF,MAAMC,MAAM,GAAG,MAAMb,QAAQ,CAACc,IAAI,CAAC,CAAC;MACpC,MAAMM,MAAM,GAAGP,MAAM,CAACE,OAAO,CAAC,CAAC,CAAC,CAACC,OAAO,CAACN,OAAO,CAACW,IAAI,CAAC,CAAC;MAEvD,IAAImB,UAAe;MACnB,IAAI;QACF;QACA,MAAMC,SAAS,GAAGrB,MAAM,CAACsB,KAAK,CAAC,4BAA4B,CAAC;QAC5D,MAAMC,QAAQ,GAAGF,SAAS,GAAGA,SAAS,CAAC,CAAC,CAAC,GAAGrB,MAAM;QAClDoB,UAAU,GAAGnC,IAAI,CAACkB,KAAK,CAACoB,QAAQ,CAAC;MACnC,CAAC,CAAC,MAAM;QACN,MAAM,IAAIxB,KAAK,CAAC,iCAAiC,CAAC;MACpD;MAEA,MAAMyB,iBAAsC,GAAG,EAAE;MAEjDJ,UAAU,CAAClE,IAAI,CAACW,OAAO,CAAC,CAACR,IAAS,EAAEyD,KAAa,KAAK;QACpD,MAAMW,KAAK,GAAGpE,IAAI,CAACqE,KAAK;QACxB,MAAMC,QAAQ,GAAGtE,IAAI,CAACuE,QAAQ;;QAE9B;QACA,MAAMC,UAAU,GAAG,IAAIC,GAAG,CAACL,KAAK,CAACzD,WAAW,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAAC;QAC5D,MAAM8D,aAAa,GAAG,IAAID,GAAG,CAACH,QAAQ,CAAC3D,WAAW,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAAC;QAClE,MAAM+D,SAAS,GAAG,IAAIF,GAAG,CAACG,KAAK,CAACC,IAAI,CAACL,UAAU,CAAC,CAACM,MAAM,CAACF,KAAK,CAACC,IAAI,CAACH,aAAa,CAAC,CAAC,CAAC;QAEnF,MAAMK,cAAc,GAAGlB,WAAW,CAAC9D,MAAM,CAACiF,OAAO,IAC/C,CAACL,SAAS,CAACM,GAAG,CAACD,OAAO,CAACrE,WAAW,CAAC,CAAC,CACtC,CAAC;QAED,MAAMuE,cAAc,GAAGH,cAAc,CAACI,KAAK,CAAC,CAAC,EAAE,EAAE,CAAC,CAACrB,IAAI,CAAC,GAAG,CAAC,CAAC,CAAC;;QAE9DK,iBAAiB,CAACiB,IAAI,CAAC;UACrBf,KAAK,EAAED,KAAK;UACZG,QAAQ,EAAED,QAAQ;UAClBe,QAAQ,EAAEH,cAAc;UACxBI,YAAY,EAAElB,KAAK,CAACV,MAAM;UAC1B6B,eAAe,EAAEjB,QAAQ,CAACZ,MAAM;UAChC8B,eAAe,EAAEN,cAAc,CAACxB,MAAM;UACtC+B,YAAY,EAAE,CAAC;UAAE;UACjBC,gBAAgB,EAAE,CAAC;UAAE;UACrBC,cAAc,EAAE,CAAC;UAAE;UACnBC,kBAAkB,EAAE,CAAC;UAAE;UACvBC,sBAAsB,EAAE,CAAC,CAAC;QAC5B,CAAC,CAAC;MACJ,CAAC,CAAC;MAEF,OAAO1B,iBAAiB;IAE1B,CAAC,CAAC,OAAO1B,KAAK,EAAE;MACdD,OAAO,CAACC,KAAK,CAAC,kCAAkC,EAAEA,KAAK,CAAC;MACxD,MAAMA,KAAK;IACb;EACF;;EAEA;EACA,OAAOqD,oBAAoBA,CACzB3B,iBAAsC,EACtC4B,YAA2B,EACoD;IAE/E,MAAMC,eAAiC,GAAG,EAAE;IAE5C,MAAMC,wBAAwB,GAAG9B,iBAAiB,CAACnD,GAAG,CAAChB,IAAI,IAAI;MAAA,IAAAkG,WAAA,EAAAC,cAAA,EAAAC,cAAA;MAC7D,MAAM5B,UAAU,GAAG,IAAIC,GAAG,CAAC,EAAAyB,WAAA,GAAAlG,IAAI,CAACqE,KAAK,cAAA6B,WAAA,uBAAVA,WAAA,CAAYvF,WAAW,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,KAAI,EAAE,CAAC;MACxE,MAAM8D,aAAa,GAAG,IAAID,GAAG,CAAC,EAAA0B,cAAA,GAAAnG,IAAI,CAACuE,QAAQ,cAAA4B,cAAA,uBAAbA,cAAA,CAAexF,WAAW,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,KAAI,EAAE,CAAC;MAC9E,MAAMyF,aAAa,GAAG,IAAI5B,GAAG,CAAC,EAAA2B,cAAA,GAAApG,IAAI,CAACqF,QAAQ,cAAAe,cAAA,uBAAbA,cAAA,CAAezF,WAAW,CAAC,CAAC,CAACC,KAAK,CAAC,GAAG,CAAC,KAAI,EAAE,CAAC;MAE5E,MAAM0F,aAAa,GAAG,IAAI7B,GAAG,CAC3BG,KAAK,CAACC,IAAI,CAACL,UAAU,CAAC,CACnBM,MAAM,CAACF,KAAK,CAACC,IAAI,CAACH,aAAa,CAAC,CAAC,CACjCI,MAAM,CAACF,KAAK,CAACC,IAAI,CAACwB,aAAa,CAAC,CACrC,CAAC;MAED,IAAIE,WAAW,GAAG,CAAC;MACnB,IAAIC,eAAe,GAAG,CAAC;MACvB,IAAIC,YAAY,GAAG,CAAC;MAEpBV,YAAY,CAACvF,OAAO,CAACkG,GAAG,IAAI;QAC1B,MAAMC,YAAY,GAAG,IAAIlC,GAAG,CAACiC,GAAG,CAAChG,OAAO,CAACC,WAAW,CAAC,CAAC,CAACC,KAAK,CAAC,KAAK,CAAC,CAAC;;QAEpE;QACA,MAAMgG,OAAO,GAAGhC,KAAK,CAACC,IAAI,CAAC8B,YAAY,CAAC,CAACE,KAAK,CAAChG,IAAI,IACjD+D,KAAK,CAACC,IAAI,CAACyB,aAAa,CAAC,CAACQ,IAAI,CAACC,YAAY,IACzCA,YAAY,CAAC7D,QAAQ,CAACrC,IAAI,CAAC,IAAIA,IAAI,CAACqC,QAAQ,CAAC6D,YAAY,CAC3D,CACF,CAAC;QAED,IAAIH,OAAO,EAAE;UACXL,WAAW,IAAIG,GAAG,CAACzG,MAAM;UACzBuG,eAAe,IAAIE,GAAG,CAACxG,UAAU;UACjCuG,YAAY,EAAE;UAEdT,eAAe,CAACZ,IAAI,CAAC;YACnBJ,OAAO,EAAE0B,GAAG,CAAChG,OAAO;YACpBsG,MAAM,EAAEN,GAAG,CAACzG,MAAM;YAClBgH,UAAU,EAAEP,GAAG,CAACxG;UAClB,CAAC,CAAC;QACJ;MACF,CAAC,CAAC;MAEF,OAAO;QACL,GAAGF,IAAI;QACPyF,YAAY,EAAEc,WAAW;QACzBb,gBAAgB,EAAEc,eAAe;QACjCb,cAAc,EAAEc,YAAY,GAAG,CAAC,GAAGS,IAAI,CAACC,KAAK,CAACZ,WAAW,GAAGE,YAAY,GAAG,IAAI,CAAC,GAAG,IAAI,GAAG,CAAC;QAC3Fb,kBAAkB,EAAEa,YAAY,GAAG,CAAC,GAAGS,IAAI,CAACC,KAAK,CAACX,eAAe,GAAGC,YAAY,GAAG,IAAI,CAAC,GAAG,IAAI,GAAG,CAAC;QACnGZ,sBAAsB,EAAEY;MAC1B,CAAC;IACH,CAAC,CAAC;IAEF,OAAO;MACLtC,iBAAiB,EAAE8B,wBAAwB;MAC3CD;IACF,CAAC;EACH;;EAEA;EACA,aAAaoB,oBAAoBA,CAC/BvH,IAAmB,EACnB+D,OAAe,EACfR,eAAuB,EACvBtD,eAAuB,EACiE;IAExF;IACA,IAAI,CAACD,IAAI,IAAIA,IAAI,CAAC6D,MAAM,KAAK,CAAC,EAAE;MAC9B,MAAM,IAAIhB,KAAK,CAAC,iCAAiC,CAAC;IACpD;IAEA,IAAI,CAACkB,OAAO,IAAIA,OAAO,CAAChB,IAAI,CAAC,CAAC,KAAK,EAAE,EAAE;MACrC,MAAM,IAAIF,KAAK,CAAC,sBAAsB,CAAC;IACzC;IAEA,IAAI,CAACU,eAAe,IAAIA,eAAe,CAACR,IAAI,CAAC,CAAC,KAAK,EAAE,EAAE;MACrD,MAAM,IAAIF,KAAK,CAAC,+BAA+B,CAAC;IAClD;;IAEA;IACA,MAAM2E,OAAO,GAAG,IAAI,CAACzH,aAAa,CAACC,IAAI,EAAEC,eAAe,CAAC;IACzD,IAAIuH,OAAO,CAAC3D,MAAM,KAAK,CAAC,EAAE;MACxB,MAAM,IAAIhB,KAAK,CAAC,qDAAqD5C,eAAe,wCAAwC,CAAC;IAC/H;;IAEA;IACA,MAAMqB,eAAe,GAAG,IAAI,CAACb,qBAAqB,CAAC+G,OAAO,CAAC;IAC3D,IAAIlG,eAAe,CAACuC,MAAM,KAAK,CAAC,EAAE;MAChC,MAAM,IAAIhB,KAAK,CAAC,sDAAsD,CAAC;IACzE;;IAEA;IACA,MAAM4E,cAAc,GAAG,MAAM,IAAI,CAACpG,kBAAkB,CAACC,eAAe,CAAC;IACrE,IAAImG,cAAc,CAAC5D,MAAM,KAAK,CAAC,EAAE;MAC/B,MAAM,IAAIhB,KAAK,CAAC,iDAAiD,CAAC;IACpE;;IAEA;IACA,MAAM6E,eAAe,GAAG,MAAM,IAAI,CAACpE,cAAc,CAACmE,cAAc,EAAElE,eAAe,CAAC;IAClF,IAAImE,eAAe,CAAC7D,MAAM,KAAK,CAAC,EAAE;MAChC,MAAM,IAAIhB,KAAK,CAAC,4CAA4C,CAAC;IAC/D;;IAEA;IACA,MAAMyB,iBAAiB,GAAG,MAAM,IAAI,CAACR,qBAAqB,CAAC4D,eAAe,EAAE3D,OAAO,EAAER,eAAe,CAAC;IACrG,IAAIe,iBAAiB,CAACT,MAAM,KAAK,CAAC,EAAE;MAClC,MAAM,IAAIhB,KAAK,CAAC,4CAA4C,CAAC;IAC/D;;IAEA;IACA,MAAMN,MAAM,GAAG,IAAI,CAAC0D,oBAAoB,CAAC3B,iBAAiB,EAAEtE,IAAI,CAAC;IAEjE,OAAOuC,MAAM;EACf;AACF","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}