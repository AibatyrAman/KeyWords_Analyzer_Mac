2025-08-25 13:15:41,888 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-08-25 13:15:41,888 - DEBUG - api_version=None data='{"model": "gpt-4", "messages": [{"role": "system", "content": "\\nYou are an expert in identifying branded words and proper nouns. Your task is to determine if the given words are branded words or proper nouns (like \\"Williams\\", \\"Sherwin\\", etc.).\\nYou need to identify and return only the words that are branded or proper nouns from the provided list.\\n\\nHere is the task in detail:\\n1. Review the following list of words.\\n2. Identify the branded words and proper nouns.\\n3. Return the list of identified branded words and proper nouns in the following format:\\n\\nExample:\\n- Input: [\\"Apple\\", \\"car\\", \\"Sherwin\\", \\"painting\\"]\\n- Output: [\\"Apple\\", \\"Sherwin\\"]\\n\\n*Important*: \\n- Only include the branded words and proper nouns in the returned list, and avoid any other words."}, {"role": "user", "content": "\\n            Here is the list of words:\\n            [\'app\', \'free\', \'my\', \'ai\', \'for\', \'first\', \'tracker\', \'portal\', \'parent\', \'bible\', \'k\', \'iphone\', \'real\', \'baby\', \'editor\', \'photo\', \'emoji\', \'and\', \'football\', \'live\', \'pregnancy\', \'big\', \'madrid\', \'10\', \'noise\', \'12\', \'student\', \'ringtones\', \'tiny\', \'text\', \'book\', \'shop\', \'audio\', \'nfl\', \'hurricane\', \'player\', \'news\', \'pray\', \'plus\', \'watch\', \'the\', \'apple\', \'maker\', \'alert\', \'tsunami\', \'pattino\', \'generator\', \'view\', \'bus\', \'tracking\', \'eba\', \'yuca\', \'food\', \'scanner\', \'doctor\', \'online\', \'bags\', \'\\u0633\\u064a\\u0646\\u0648\\u0645\\u064a\', \'\\u0628\\u0644\\u0633\', \'logo\', \'times\', \'of\', \'london\', \'wheresthebus\', \'pop\', \'demon\', \'hunters\', \'piano\', \'benefits\', \'screen\', \'singlecare\', \'atlanta\', \'healthy\', \'temp\', \'email\', \'k12\', \'ols\', \'blend\', \'photos\', \'thsba\', \'4d\', \'wallpaper\', \'ukulele\', \'runyourpool\', \'uhcsr\', \'foxchat\', \'jets\', \'music\', \'offline\', \'outbreak\', \'stay\', \'premium\', \'seminary\', \'id\', \'edurooms\', \'acustic\', \'guitar\', \'tuner\', \'play\', \'myayo\', \'flower\', \'identify\', \'awn\', \'bookshop\', \'reader\', \'clear\', \'politics\', \'scores\', \'ride\', \'style\', \'libre\', \'3\', \'newsbang\', \'skyward\', \'eraser\', \'mcps\', \'libgen\', \'ligue\', \'1\', \'carline\', \'hound\', \'object\', \'note\', \'de\', \'padres\', \'sub\', \'macmillan\', \'learning\', \'ebook\', \'medical\', \'go\', \'guardian\', \'faceage\', \'antivirus\', \'myreaxiumapp\', \'tv\', \'union\', \'big10\', \'whatnot\', \'credit\', \'shopping\', \'capital\', \'picture\', \'stop\', \'nachc\', \'mobile\', \'math\', \'myseminary\', \'voscreen\', \'learn\', \'english\', \'gpt\', \'background\', \'meditation\', \'adult\', \'singles\', \'bswhealth\', \'motley\', \'fool\', \'adobe\', \'pdf\', \'viewer\', \'hotlunch\', \'los\', \'angeles\', \'rams\', \'one\', \'chart\', \'newsletter\', \'\\u062e\\u0631\\u0627\\u0626\\u0637\', \'\\u0627\\u0644\\u0645\\u0637\\u0631\', \'\\u0432\\u0430\\u0439\\u0431\\u0435\\u0440\\u0438\\u0441\', \'spam\', \'call\', \'relaxation\', \'blocker\', \'essay\', \'twitter\', \'video\', \'downloader\', \'ap\', \'college\', \'board\', \'make\', \'invites\', \'boost\', \'phone\', \'wattpad\', \'read\', \'write\', \'stories\', \'blgo\', \'llve\', \'realtime\', \'plant\', \'tree\', \'identification\', \'mail\', \'streaming\', \'track\', \'t\', \'khealth\', \'thefabstory\', \'birthday\', \'party\', \'invitations\', \'life\', \'time\', \'fitness\', \'5d\', \'planner\', \'voice\', \'sberkids\', \'slader\', \'control\', \'remoto\', \'samsung\', \'guarh\', \'answer\', \'kjv\', \'audiobook\', \'twin\', \'wowt\', \'6\', \'weight\', \'loss\', \'sleep\', \'sec\', \'volleymetrics\', \'kimi\\u667a\\u80fd\\u52a9\\u624b\', \'gauthmath\', \'trek\', \'bicycle\', \'rotobot\', \'pollen\', \'count\', \'healing\', \'frequencies\', \'inklab\', \'dexcom\', \'follow\', \'5\', \'0\', \'network\', \'health\', \'\\u062b\\u0645\\u0627\\u0646\\u064a\\u0629\', \'darato\', \'myride\', \'6s\', \'7\', \'smart\', \'tag\', \'weather\', \'edulog\', \'alabama\', \'versatrans\', \'seesaw\', \'\\u549a\\u6f2b\']\\n\\n            Return the list of branded words and proper nouns in the following format:\\n            [\\"word1\\", \\"word2\\", \\"word3\\"]\\n            "}], "temperature": 0, "max_tokens": 150}' message='Post details'
2025-08-25 13:15:41,889 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-08-25 13:15:41,893 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-08-25 13:15:42,385 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 401 414
2025-08-25 13:15:42,386 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=None request_id=req_083ce41586d644a9befd5f71aba47e33 response_code=401
2025-08-25 13:15:42,386 - INFO - error_code=invalid_api_key error_message='Incorrect API key provided: sk-proj-********************************************************************************************************************************************************1RoA. You can find your API key at https://platform.openai.com/account/api-keys.' error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False
2025-08-25 13:19:25,379 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-08-25 13:19:25,380 - DEBUG - api_version=None data='{"model": "gpt-4", "messages": [{"role": "system", "content": "\\nYou are an expert in identifying branded words and proper nouns. Your task is to determine if the given words are branded words or proper nouns (like \\"Williams\\", \\"Sherwin\\", etc.).\\nYou need to identify and return only the words that are branded or proper nouns from the provided list.\\n\\nHere is the task in detail:\\n1. Review the following list of words.\\n2. Identify the branded words and proper nouns.\\n3. Return the list of identified branded words and proper nouns in the following format:\\n\\nExample:\\n- Input: [\\"Apple\\", \\"car\\", \\"Sherwin\\", \\"painting\\"]\\n- Output: [\\"Apple\\", \\"Sherwin\\"]\\n\\n*Important*: \\n- Only include the branded words and proper nouns in the returned list, and avoid any other words."}, {"role": "user", "content": "\\n            Here is the list of words:\\n            [\'app\', \'free\', \'my\', \'ai\', \'for\', \'first\', \'tracker\', \'portal\', \'parent\', \'bible\', \'k\', \'iphone\', \'real\', \'baby\', \'editor\', \'photo\', \'emoji\', \'and\', \'football\', \'live\', \'pregnancy\', \'big\', \'madrid\', \'10\', \'noise\', \'12\', \'student\', \'ringtones\', \'tiny\', \'text\', \'book\', \'shop\', \'audio\', \'nfl\', \'hurricane\', \'player\', \'news\', \'pray\', \'plus\', \'watch\', \'the\', \'apple\', \'maker\', \'alert\', \'tsunami\', \'pattino\', \'generator\', \'view\', \'bus\', \'tracking\', \'eba\', \'yuca\', \'food\', \'scanner\', \'doctor\', \'online\', \'bags\', \'\\u0633\\u064a\\u0646\\u0648\\u0645\\u064a\', \'\\u0628\\u0644\\u0633\', \'logo\', \'times\', \'of\', \'london\', \'wheresthebus\', \'pop\', \'demon\', \'hunters\', \'piano\', \'benefits\', \'screen\', \'singlecare\', \'atlanta\', \'healthy\', \'temp\', \'email\', \'k12\', \'ols\', \'blend\', \'photos\', \'thsba\', \'4d\', \'wallpaper\', \'ukulele\', \'runyourpool\', \'uhcsr\', \'foxchat\', \'jets\', \'music\', \'offline\', \'outbreak\', \'stay\', \'premium\', \'seminary\', \'id\', \'edurooms\', \'acustic\', \'guitar\', \'tuner\', \'play\', \'myayo\', \'flower\', \'identify\', \'awn\', \'bookshop\', \'reader\', \'clear\', \'politics\', \'scores\', \'ride\', \'style\', \'libre\', \'3\', \'newsbang\', \'skyward\', \'eraser\', \'mcps\', \'libgen\', \'ligue\', \'1\', \'carline\', \'hound\', \'object\', \'note\', \'de\', \'padres\', \'sub\', \'macmillan\', \'learning\', \'ebook\', \'medical\', \'go\', \'guardian\', \'faceage\', \'antivirus\', \'myreaxiumapp\', \'tv\', \'union\', \'big10\', \'whatnot\', \'credit\', \'shopping\', \'capital\', \'picture\', \'stop\', \'nachc\', \'mobile\', \'math\', \'myseminary\', \'voscreen\', \'learn\', \'english\', \'gpt\', \'background\', \'meditation\', \'adult\', \'singles\', \'bswhealth\', \'motley\', \'fool\', \'adobe\', \'pdf\', \'viewer\', \'hotlunch\', \'los\', \'angeles\', \'rams\', \'one\', \'chart\', \'newsletter\', \'\\u062e\\u0631\\u0627\\u0626\\u0637\', \'\\u0627\\u0644\\u0645\\u0637\\u0631\', \'\\u0432\\u0430\\u0439\\u0431\\u0435\\u0440\\u0438\\u0441\', \'spam\', \'call\', \'relaxation\', \'blocker\', \'essay\', \'twitter\', \'video\', \'downloader\', \'ap\', \'college\', \'board\', \'make\', \'invites\', \'boost\', \'phone\', \'wattpad\', \'read\', \'write\', \'stories\', \'blgo\', \'llve\', \'realtime\', \'plant\', \'tree\', \'identification\', \'mail\', \'streaming\', \'track\', \'t\', \'khealth\', \'thefabstory\', \'birthday\', \'party\', \'invitations\', \'life\', \'time\', \'fitness\', \'5d\', \'planner\', \'voice\', \'sberkids\', \'slader\', \'control\', \'remoto\', \'samsung\', \'guarh\', \'answer\', \'kjv\', \'audiobook\', \'twin\', \'wowt\', \'6\', \'weight\', \'loss\', \'sleep\', \'sec\', \'volleymetrics\', \'kimi\\u667a\\u80fd\\u52a9\\u624b\', \'gauthmath\', \'trek\', \'bicycle\', \'rotobot\', \'pollen\', \'count\', \'healing\', \'frequencies\', \'inklab\', \'dexcom\', \'follow\', \'5\', \'0\', \'network\', \'health\', \'\\u062b\\u0645\\u0627\\u0646\\u064a\\u0629\', \'darato\', \'myride\', \'6s\', \'7\', \'smart\', \'tag\', \'weather\', \'edulog\', \'alabama\', \'versatrans\', \'seesaw\', \'\\u549a\\u6f2b\']\\n\\n            Return the list of branded words and proper nouns in the following format:\\n            [\\"word1\\", \\"word2\\", \\"word3\\"]\\n            "}], "temperature": 0, "max_tokens": 150}' message='Post details'
2025-08-25 13:19:25,380 - DEBUG - Converted retries value: 2 -> Retry(total=2, connect=None, read=None, redirect=None, status=None)
2025-08-25 13:19:25,384 - DEBUG - Starting new HTTPS connection (1): api.openai.com:443
2025-08-25 13:19:32,711 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-08-25 13:19:32,721 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=6201 request_id=req_784641230a904ab0bd67d075bf164c3c response_code=200
2025-08-25 13:19:40,117 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-08-25 13:19:40,117 - DEBUG - api_version=None data='{"model": "gpt-4o", "messages": [{"role": "system", "content": "\\n            You are an expert in language processing. Your task is:\\n1. Given a Python list of keywords in the language relevant to the market of Thailand,\\n2. Remove only the plural suffixes from each word to return the singular/base form. For example, if the keywords are in English (as in the Thailand market when applicable), remove plural suffixes such as -s, -es, and -ies. If the keywords are in another language, apply the appropriate plural suffix removal rules according to the language conventions of Thailand.\\n3. If a word does not end with any of these plural suffixes, leave it unchanged.\\n4. Provide the final answer strictly as a Python list of strings.\\nExample:\\n- Input: [\\"cats\\", \\"boxes\\", \\"stories\\", \\"apple\\"]\\n- Output: [\\"cat\\", \\"box\\", \\"story\\", \\"apple\\"]\\n\\n**WARNING**: Only remove plural suffixes. Do not remove any other suffix or modify the word in any other way.\\n"}, {"role": "user", "content": "\\n            Here is the list of words:\\n            [\'ai\', \'first\', \'tracker\', \'portal\', \'parent\', \'bible\', \'k\', \'real\', \'baby\', \'editor\', \'photo\', \'emoji\', \'football\', \'live\', \'pregnancy\', \'big\', \'10\', \'noise\', \'12\', \'student\', \'ringtones\', \'tiny\', \'text\', \'book\', \'shop\', \'audio\', \'hurricane\', \'player\', \'news\', \'pray\', \'plus\', \'watch\', \'maker\', \'alert\', \'tsunami\', \'generator\', \'view\', \'bus\', \'tracking\', \'food\', \'scanner\', \'doctor\', \'online\', \'bags\', \'\\u0633\\u064a\\u0646\\u0648\\u0645\\u064a\', \'\\u0628\\u0644\\u0633\', \'logo\', \'times\', \'pop\', \'piano\', \'benefits\', \'screen\', \'healthy\', \'temp\', \'email\', \'blend\', \'photos\', \'4d\', \'wallpaper\', \'music\', \'offline\', \'stay\', \'premium\', \'id\', \'acustic\', \'guitar\', \'tuner\', \'play\', \'flower\', \'identify\', \'reader\', \'clear\', \'politics\', \'scores\', \'ride\', \'style\', \'libre\', \'3\', \'eraser\', \'1\', \'object\', \'note\', \'de\', \'padres\', \'sub\', \'medical\', \'guardian\', \'faceage\', \'antivirus\', \'myreaxiumapp\', \'tv\', \'union\', \'big10\', \'whatnot\', \'credit\', \'shopping\', \'capital\', \'picture\', \'stop\', \'nachc\', \'mobile\', \'math\', \'myseminary\', \'voscreen\', \'learn\', \'english\', \'gpt\', \'background\', \'meditation\', \'adult\', \'singles\', \'bswhealth\', \'motley\', \'fool\', \'adobe\', \'pdf\', \'viewer\', \'hotlunch\', \'los\', \'angeles\', \'rams\', \'one\', \'chart\', \'newsletter\', \'\\u062e\\u0631\\u0627\\u0626\\u0637\', \'\\u0627\\u0644\\u0645\\u0637\\u0631\', \'\\u0432\\u0430\\u0439\\u0431\\u0435\\u0440\\u0438\\u0441\', \'spam\', \'call\', \'relaxation\', \'blocker\', \'essay\', \'twitter\', \'video\', \'downloader\', \'ap\', \'college\', \'board\', \'make\', \'invites\', \'boost\', \'phone\', \'wattpad\', \'read\', \'write\', \'stories\', \'blgo\', \'llve\', \'realtime\', \'plant\', \'tree\', \'identification\', \'mail\', \'streaming\', \'track\', \'t\', \'khealth\', \'thefabstory\', \'birthday\', \'party\', \'invitations\', \'life\', \'time\', \'fitness\', \'5d\', \'planner\', \'voice\', \'sberkids\', \'slader\', \'control\', \'remoto\', \'samsung\', \'guarh\', \'answer\', \'kjv\', \'audiobook\', \'twin\', \'wowt\', \'6\', \'weight\', \'loss\', \'sleep\', \'sec\', \'volleymetrics\', \'kimi\\u667a\\u80fd\\u52a9\\u624b\', \'gauthmath\', \'trek\', \'bicycle\', \'rotobot\', \'pollen\', \'count\', \'healing\', \'frequencies\', \'inklab\', \'dexcom\', \'follow\', \'5\', \'0\', \'network\', \'health\', \'\\u062b\\u0645\\u0627\\u0646\\u064a\\u0629\', \'darato\', \'myride\', \'6s\', \'7\', \'smart\', \'tag\', \'weather\', \'edulog\', \'alabama\', \'versatrans\', \'seesaw\', \'\\u549a\\u6f2b\']\\n\\n            Return the processed list in JSON list format. For example:\\n            [\\"word1\\",\\"word2\\",\\"word3\\"]\\n            "}], "temperature": 0}' message='Post details'
2025-08-25 13:19:44,547 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-08-25 13:19:44,555 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=3901 request_id=req_931782834147422b8c02941f9381555f response_code=200
2025-08-25 13:19:57,920 - DEBUG - message='Request to OpenAI API' method=post path=https://api.openai.com/v1/chat/completions
2025-08-25 13:19:57,921 - DEBUG - api_version=None data='{"model": "chatgpt-4o-latest", "messages": [{"role": "system", "content": "\\n    You are an experienced ASO (App Store Optimization) expert. Your task is to generate optimized Title and Subtitle for an app based on the provided keyword data.\\n    I will provide you with a list of keywords sorted by frequency. Based on this information, your task is to generate the most optimized Title and Subtitle for an app\'s App Store page. Here are the detailed rules:\\n    You are an experienced ASO (App Store Optimization) expert. Your task is to generate optimized Title and Subtitle for an app based on the provided keyword data, taking into account the market characteristics of the selected country: **Thailand**.\\nI will provide you with a list of keywords sorted by frequency. Based on this information, your task is to generate the most optimized Title and Subtitle for an app\'s App Store page for the Thailand market. Here are the detailed rules:\\n\\n    1. **Title**:\\n    - Must include the app name: **Deco**\\n    - The title must be no longer than **30 characters** and no shorter than **25 characters**.\\n    - Use the most frequent keywords first, prioritizing those at the beginning of the provided list.\\n    - Ensure that the titles are unique and not repetitive; each generated title should use a different combination of keywords.\\n    - **Do not include any of the following words like: \\"and\\", \\"or\\", \\"your\\", \\"my\\", \\"with\\", etc.**\\n\\n    2. **Subtitle**:\\n    - It must not exceed **30 characters** and no shorter than **25 characters**.\\n    - Do not repeat any keywords used in the Title.\\n    - Use the most frequent keywords first, prioritizing those at the beginning of the provided list.\\n    - Ensure that the subtitles are unique and distinct from each other.\\n    - **Do not include any of the following words like: \\"and\\", \\"or\\", \\"your\\", \\"my\\", \\"with\\".**\\n\\n    3. **Important**:\\n    - Focus on using keywords from the beginning of the provided list, where the frequency values are higher.\\n    - Make sure the Title and Subtitle align with these rules to maximize the app\'s visibility and effectiveness in the App Store.\\n    - **Do not include any of the following words like: \\"and\\", \\"or\\", \\"your\\", \\"my\\", \\"with\\".**\\n    - *Only generate 5 title and 5 subtitle*\\n    "}, {"role": "user", "content": "\\n    Here are the most frequent keywords:\\n    ai,first,photo,tracker,editor,bible,portal,k,parent,real,baby,audio,10,emoji,book,alert,big,hurricane,football,maker,ringtone,tiny,news,player,pray,plus,pregnancy,live,noise,12,shop,text,time,watch,student,answer,angeles,alabama,adult,acustic,adobe,6s,7,5,4d,bicycle,big10,birthday,blend,blgo,antivirus,dexcom,de,darato,credit,count,email,edulog,downloader,eraser,essay,faceage,bag,benefit,audiobook,ap,background,blocker,board,boost,bswhealth,bus,call,capital,chart,clear,college,control,0,5d,6,1,3,identify,identification,id,hotlunch,health,healthy,healing,guitar,generator,guarh,guardian,gpt,frequency,gauthmath,food,fool,doctor,english,follow,flower,fitness,mobile,math,medical,mail,loss,los,make,meditation,khealth,invitation,inklab,newsletter,network,myseminary,nachc,myride,myreaxiumapp,motley,music,party,pdf,offline,note,one,online,padres,object,play,plant,planner,picture,piano,phone,pollen,politics,learn,libre,life,llve,logo,kimi\\u667a\\u80fd\\u52a9\\u624b,kjv,invite,remoto,relaxation,realtime,reader,ram,read,premium,pop,screen,sec,seesaw,shopping,sberkids,scanner,rotobot,ride,smart,sleep,slader,single,story,spam,stop,stay,sub,style,streaming,t,temp,tag,score,samsung,track,thefabstory,tree,tracking,tsunami,tuner,tv,trek,twitter,union,versatrans,video,view,viewer,voice,twin,volleymetrics,voscreen,wallpaper,wattpad,weather,weight,whatnot,wowt,write,\\u0432\\u0430\\u0439\\u0431\\u0435\\u0440\\u0438\\u0441,\\u0627\\u0644\\u0645\\u0637\\u0631,\\u0628\\u0644\\u0633,\\u062b\\u0645\\u0627\\u0646\\u064a\\u0629,\\u062e\\u0631\\u0627\\u0626\\u0637,\\u0633\\u064a\\u0646\\u0648\\u0645\\u064a,\\u549a\\u6f2b\\n    - **The title and subtitle must be no longer than 30 characters and no shorter than 25 characters.**\\n    - **Do not include any of the following words like: \\"and\\", \\"or\\", \\"your\\", \\"my\\", \\"with\\".**\\n    - *Only generate 5 title and 5 subtitle*\\n    **Provide the output strictly in the following JSON format:**\\n    json\\n    {\\n    \\"data\\": [\\n        {\\"Title\\": \\"Generated Title\\", \\"Subtitle\\": \\"Generated Subtitle\\"},\\n        {\\"Title\\": \\"Generated Title\\", \\"Subtitle\\": \\"Generated Subtitle\\"},\\n        {\\"Title\\": \\"Generated Title\\", \\"Subtitle\\": \\"Generated Subtitle\\"},\\n        {\\"Title\\": \\"Generated Title\\", \\"Subtitle\\": \\"Generated Subtitle\\"},\\n        {\\"Title\\": \\"Generated Title\\", \\"Subtitle\\": \\"Generated Subtitle\\"}\\n    ]\\n    }\\n    "}], "temperature": 0.7, "max_tokens": 539}' message='Post details'
2025-08-25 13:19:59,989 - DEBUG - https://api.openai.com:443 "POST /v1/chat/completions HTTP/1.1" 200 None
2025-08-25 13:19:59,993 - DEBUG - message='OpenAI API response' path=https://api.openai.com/v1/chat/completions processing_ms=1795 request_id=req_19a933ff0e4f41248ddc4ac3dd873fdd response_code=200
